[?2004hroot@76c15cab1a93:/backup# asciinema rec --stdin /logs/agent.cast
[?2004l[0;32masciinema: recording asciicast to /logs/agent.cast[0m
[0;32masciinema: press <ctrl-d> or type "exit" when you're done[0m
[?2004hroot@76c15cab1a93:/backup# clear
[?2004l[H[J[3J[?2004hroot@76c15cab1a93:/backup# ls -la /backup/; tmux wait -S done
[?2004ltotal 40
drwxr-xr-x 1 root root  4096 Dec  4 16:59 [0m[01;34m.[0m
drwxr-xr-x 1 root root  4096 Dec  4 19:03 [01;34m..[0m
-rw-r--r-- 1 root root   945 Dec  4 16:54 backup_metadata.log
-rw-r--r-- 1 root root   718 Dec  4 16:54 database.sql
-rw-r--r-- 1 root root   703 Dec  4 16:54 postgresql.conf
-rw-r--r-- 1 root root 15425 Dec  4 16:54 transactions_backup.json
-rw-r--r-- 1 root root  2351 Dec  4 16:54 users_export.csv
[?2004hroot@76c15cab1a93:/backup# service postgresql start; tmux wait -S done
[?2004l * Starting PostgreSQL 16 database server       [160G [154G[ OK ]
[?2004hroot@76c15cab1a93:/backup# cat /backup/backup_metadata.log; tmux wait -S done
[?2004l[2025-09-28 03:00:00] INFO: Starting database backup process
[2025-09-28 03:00:01] INFO: Backup initiated by: admin
[2025-09-28 03:00:01] INFO: Backup type: Full
[2025-09-28 03:00:02] INFO: Connecting to database: production_db
[2025-09-28 03:00:03] INFO: Connection successful
[2025-09-28 03:00:05] INFO: Backing up table: users
[2025-09-28 03:00:06] INFO: Table 'users' backed up successfully - 30 rows
[2025-09-28 03:00:07] INFO: Backing up table: transactions
[2025-09-28 03:00:09] INFO: Table 'transactions' backed up successfully - 100 rows
[2025-09-28 03:00:10] INFO: Total tables backed up: 2
[2025-09-28 03:00:10] INFO: Total rows backed up: 130
[2025-09-28 03:00:11] INFO: Running integrity check
[2025-09-28 03:00:12] INFO: Integrity check: PASSED
[2025-09-28 03:00:13] INFO: Backup completed successfully
[2025-09-28 03:00:13] INFO: Backup file: /backup/database.sql
[2025-09-28 03:00:13] INFO: Backup timestamp: 2025-09-28 03:00:00
[?2004hroot@76c15cab1a93:/backup# head -20 /backup/database.sql; tmux wait -S done
[?2004l-- PostgreSQL database dump
-- This dump contains the schema and some sample data
-- Note: Some statements may have errors that need to be fixed

-- Create users table
CREATE TABLE IF NOT EXISTS users (
    user_id INTEGER PRIMARY KEY,
    username VARCHAR(100) NOT NULL,
    email VARCHAR(255) NOT NULL,
    created_at TIMESTAMP,
    status VARCHAR(20)
);

-- Create transactions table  
CREATE TABLE IF NOT EXISTS transactions (
    transaction_id INTEGER PRIMARY KEY,
    user_id INTEGER,
    amount DECIMAL(10,2),
    timestamp TIMESTAMP,
    description TEXT,
[?2004hroot@76c15cab1a93:/backup# head -20 /backup/users_export.csv; tmux wait -S done
[?2004luser_id,username,email,created_at,status
1,alice_smith,alice_smith@example.com,2024-11-21 01:25:46,inactive
2,bob_jones,bob_jones@example.com,2025-06-28 01:25:46,active
3,charlie_brown,charlie_brown@example.com,2025-08-13 01:25:46,suspended
4,diana_prince,diana_prince@example.com,2025-08-05 01:25:46,inactive
5,eve_adams,eve_adams@example.com,2025-09-08 01:25:46,inactive
6,frank_white,frank_white@example.com,2025-09-04 01:25:46,active
7,grace_lee,grace_lee@example.com,2025-06-05 01:25:46,active
8,henry_ford,henry_ford@example.com,2025-07-25 01:25:46,inactive
9,iris_west,iris_west@example.com,2025-03-23 01:25:46,suspended
10,jack_ryan,jack_ryan@example.com,2024-10-19 01:25:46,inactive
11,kate_mills,kate_mills@example.com,2025-06-27 01:25:46,active
12,leo_king,leo_king@example.com,2024-12-21 01:25:46,inactive
13,mary_jane,mary_jane@example.com,2025-10-03 01:25:46,suspended
14,nick_fury,nick_fury@example.com,2025-04-03 01:25:46,suspended
15,olivia_pope,olivia_pope@example.com,2025-06-01 01:25:46,active
16,peter_parker,peter_parker@example.com,2025-01-02 01:25:46,inactive
17,quinn_baker,quinn_baker@example.com,2025-01-22 01:25:46,suspended
18,rachel_green,rachel_green@example.com,2025-04-01 01:25:46,inactive
19,steve_rogers,steve_rogers@example.com,2025-06-28 01:25:46,active
[?2004hroot@76c15cab1a93:/backup# head -20 /backup/transactions_backup.json; tmux wait -S done
[?2004l[
  {
    "transaction_id": 1,
    "user_id": 16,
    "amount": 46.0,
    "timestamp": "2025-07-16 01:25:56",
    "description": "Subscription"
  },
  {
    "transaction_id": 2,
    "user_id": 6,
    "amount": 646.05,
    "timestamp": "2025-05-02 01:25:56",
    "description": "Payment"
  },
  {
    "transaction_id": 3,
    "user_id": 29,
    "amount": 186.76,
    "timestamp": "2025-07-30 01:25:56",
[?2004hroot@76c15cab1a93:/backup# cat > /backup/restore_database.py << 'EOF'
[?2004l[?2004h> import psycopg2
[?2004l[?2004h> import csv
[?2004l[?2004h> import json
[?2004l_id, username, email, created_at, s[?2004h> import re
[?2004l[?2004h> from decimal import Decimal
[?2004l[?2004h> 
[?2004ltatus)
            VALUES (%s, %s, %s, [?2004h> # Create database and restore schema
[?2004l[?2004h> def create_database():
[?2004l, user['username'], use[?2004h>     # Connect to default postgres database
[?2004l[?2004h>     conn = psycopg2.connect(dbname='postgres', user='postgres', host='localhost')
[?2004l[?2004h>     conn.autocommit = True
[?2004lSERT [?2004h>     cur = conn.cursor()
[?2004l[?2004h>     
[?2004l[?2004h>     # Drop if exists and create new database
[?2004l[?2004h>     cur.execute("DROP DATABASE IF EXISTS production_db")
[?2004l[?2004h>     cur.execute("CREATE DATABASE production_db")
[?2004l[?2004h>     cur.close()
[?2004ltimesta[?2004h>     conn.close()
[?2004l'de[?2004h>     
[?2004l[?2004h>     # Connect to new database and create tables
[?2004l[?2004h>     conn = psycopg2.connect(dbname='production_db', user='postgres', host='localhost')
[?2004l[?2004h>     cur = conn.cursor()
[?2004l[?2004h>     
[?2004l[?2004h>     # Create users table
[?2004l[?2004h>     cur.execute("""
[?2004lproduction_db', user='postgres', host='localhost')[?2004h>         CREATE TABLE users (
[?2004l[?2004h>             user_id INTEGER PRIMARY KEY,
[?2004l[?2004h>             username VARCHAR(255) NOT NULL,
[?2004l[?2004h>             email VARCHAR(255) NOT NULL,
[?2004l[?2004h>             created_at TIMESTAMP,
[?2004l*) FR[?2004h>             status VARCHAR(50)
[?2004l[?2004h>         )
[?2004l[?2004h>     """)
[?2004l[?2004h>     
[?2004l[?2004h>     # Create transactions table
[?2004l[?2004h>     cur.execute("""
[?2004l[?2004h>         CREATE TABLE transactions (
[?2004l[?2004h>             transaction_id INTEGER PRIMARY KEY,
[?2004l[?2004h>             user_id INTEGER,
[?2004l[?2004h>             amount DECIMAL(10, 2),
[?2004l[?2004h>             timestamp TIMESTAMP,
[?2004ltus = 'active'")
    active_users = cur.fetchone()[0]
    
    # Total transactions
    cur.execute("SELECT COUNT(*) FROM transactions")
    total_transactions = cur.fetchone()[0]
    
    # Total amount
    cur.execute("SELECT COALESCE(SUM(amount), 0) FROM transactions[?2004h>             description TEXT
[?2004l[?2004h>         )
[?2004ltchon[?2004h>     """)
[?2004l[?2004h>     
[?2004l 
 [?2004h>     conn.commit()
[?2004l[?2004h>     cur.close()
[?2004lotal[?2004h>     conn.close()
[?2004l   [?2004h> 
[?2004l[?2004h> # Clean users data
[?2004l[?2004h> def clean_users():
[?2004l[?2004h>     valid_statuses = ['active', 'inactive', 'suspended']
[?2004l[?2004h>     email_pattern = re.compile(r'^[^@]+@[^@]+$')
[?2004l[?2004h>     
[?2004lavg_per_user = 0
    
    cur.close()
    conn.close()
    
    # Write stats
    with [?2004h>     clean_data = []
[?2004lbackup/db_sta[?2004h>     with open('/backup/users_export.csv', 'r') as f:
[?2004l[?2004h>         reader = csv.DictReader(f)
[?2004l===[?2004h>         for row in reader:
[?2004lrit[?2004h>             # Check for missing user_id
[?2004l[?2004h>             if not row.get('user_id') or row['user_id'].strip() == '':
[?2004l[?2004h>                 continue
[?2004l[?2004h>             
[?2004l[?2004h>             # Check for empty username
[?2004l[?2004h>             if not row.get('username') or row['username'].strip() == '':
[?2004l[?2004h>                 continue
[?2004l[?2004h>             
[?2004l[?2004h>             # Check for invalid email
[?2004l[?2004h>             email = row.get('email', '').strip()
[?2004l[?2004h>             if not email or not email_pattern.match(email):
[?2004l[?2004h>                 continue
[?2004lute("""
        SELECT u.[?2004h>             
[?2004l[?2004h>             # Check for invalid status
[?2004l[?2004h>             status = row.get('status', '').strip().lower()
[?2004l[?2004h>             if status not in valid_statuses:
[?2004l[?2004h>                 continue
[?2004l[?2004h>             
[?2004ll_amount DESC[?2004h>             clean_data.append({
[?2004l[?2004h>                 'user_id': row['user_id'].strip(),
[?2004l[?2004h>                 'username': row['username'].strip(),
[?2004lers[?2004h>                 'email': email,
[?2004l[?2004h>                 'created_at': row.get('created_at', '').strip(),
[?2004l[?2004h>                 'status': status
[?2004l[?2004h>             })
[?2004lt'[?2004h>     
[?2004l[?2004h>     # Write cleaned data
[?2004l[?2004h>     with open('/backup/clean_users.csv', 'w', newline='') as f:
[?2004l[?2004h>         writer = csv.DictWriter(f, fieldnames=['user_id', 'username', 'email', 'created_at', 'status'])
[?2004l[?2004h>         writer.writeheader()
[?2004lackup/backup_metadata.log', '[?2004h>         writer.writerows(clean_data)
[?2004l[?2004h>     
[?2004l[?2004h>     return clean_data
[?2004l[?2004h> 
[?2004l[?2004h> # Clean transactions data
[?2004l[?2004h> def clean_transactions():
[?2004l[?2004h>     with open('/backup/transactions_backup.json', 'r') as f:
[?2004l[?2004h>         transactions = json.load(f)
[?2004limestamp:' in line[?2004h>     
[?2004l   [?2004h>     valid_transactions = []
[?2004l[?2004h>     for txn in transactions:
[?2004l[?2004h>         # Check for null transaction_id
[?2004l[?2004h>         if txn.get('transaction_id') is None:
[?2004l[?2004h>             continue
[?2004l[?2004h>         
[?2004l[?2004h>         # Check for null or negative amounts
[?2004l[?2004h>         amount = txn.get('amount')
[?2004l[?2004h>         if amount is None or amount <= 0:
[?2004l[?2004h>             continue
[?2004l [?2004h>         
[?2004l[?2004h>         # Check for missing timestamp
[?2004l    elif 'Integrity check:' in line:
          [?2004h>         if not txn.get('timestamp'):
[?2004l[?2004h>             continue
[?2004l[?2004h>         
[?2004l[?2004h>         # Check for valid user_id (1-30)
[?2004l[?2004h>         user_id = txn.get('user_id')
[?2004l[?2004h>         if user_id is None or user_id < 1 or user_id > 30:
[?2004l[?2004h>             continue
[?2004l   f.write([?2004h>         
[?2004lup [?2004h>         valid_transactions.append(txn)
[?2004lf.write[?2004h>     
[?2004l[?2004h>     # Write valid transactions
[?2004l_backed_[?2004h>     with open('/backup/valid_transactions.json', 'w') as f:
[?2004l[?2004h>         json.dump(valid_transactions, f, indent=2)
[?2004l[?2004h>         f.write('\n')
[?2004l   f.write(f'Integrity Check: {integrity_check}\n')

# Main execution
if [?2004h>     
[?2004l[?2004h>     return valid_transactions
[?2004l[?2004h> 
[?2004l[?2004h> # Import data into database
[?2004l[?2004h> def import_data(users, transactions):
[?2004l[?2004h>     conn = psycopg2.connect(dbname='production_db', user='postgres', host='localhost')
[?2004l[?2004h>     cur = conn.cursor()
[?2004l[?2004h>     
[?2004l[?2004h>     # Import users
[?2004lons()
  [?2004h>     for user in users:
[?2004l[?2004h>         cur.execute("""
[?2004l[?2004h>             INSERT INTO users (user_id, username, email, created_at, status)
[?2004l[?2004h>             VALUES (%s, %s, %s, %s, %s)
[?2004l[?2004h>         """, (user['user_id'], user['username'], user['email'], user['created_at'], user['status']))
[?2004l[?2004h>     
[?2004l[?2004h>     # Import transactions
[?2004l[?2004h>     for txn in transactions:
[?2004lco[?2004h>         cur.execute("""
[?2004l[?2004h>             INSERT INTO transactions (transaction_id, user_id, amount, timestamp, description)
[?2004l')[?2004h>             VALUES (%s, %s, %s, %s, %s)
[?2004l[?2004h>         """, (txn['transaction_id'], txn['user_id'], txn['amount'], txn['timestamp'], txn.get('description', '')))
[?2004l[?2004h>     
[?2004l[?2004h>     conn.commit()
[?2004l[?2004h>     cur.close()
[?2004l[?2004h>     conn.close()
[?2004l[?2004h> 
[?2004l[?2004h> # Generate database statistics
[?2004l[?2004h> def generate_stats():
[?2004l[?2004h>     conn = psycopg2.connect(dbname='production_db', user='postgres', host='localhost')
[?2004l[?2004h>     cur = conn.cursor()
[?2004l[?2004h>     
[?2004l[?2004h>     # Total users
[?2004l[?2004h>     cur.execute("SELECT COUNT(*) FROM users")
[?2004l[?2004h>     total_users = cur.fetchone()[0]
[?2004l[?2004h>     
[?2004l[?2004h>     # Active users
[?2004l[?2004h>     cur.execute("SELECT COUNT(*) FROM users WHERE status = 'active'")
[?2004l[?2004h>     active_users = cur.fetchone()[0]
[?2004l[?2004h>     
[?2004l[?2004h>     # Total transactions
[?2004l[?2004h>     cur.execute("SELECT COUNT(*) FROM transactions")
[?2004l[?2004h>     total_transactions = cur.fetchone()[0]
[?2004l[?2004h>     
[?2004l[?2004h>     # Total amount
[?2004l[?2004h>     cur.execute("SELECT COALESCE(SUM(amount), 0) FROM transactions")
[?2004l[?2004h>     total_amount = float(cur.fetchone()[0])
[?2004l[?2004h>     
[?2004l[?2004h>     # Average per user
[?2004l[?2004h>     if total_users > 0:
[?2004l[?2004h>         avg_per_user = total_amount / total_users
[?2004l[?2004h>     else:
[?2004l[?2004h>         avg_per_user = 0
[?2004l[?2004h>     
[?2004l[?2004h>     cur.close()
[?2004l[?2004h>     conn.close()
[?2004l[?2004h>     
[?2004l[?2004h>     # Write stats
[?2004l[?2004h>     with open('/backup/db_stats.txt', 'w') as f:
[?2004l[?2004h>         f.write('DATABASE STATISTICS\n')
[?2004l[?2004h>         f.write('==================\n')
[?2004l[?2004h>         f.write(f'Total Users: {total_users}\n')
[?2004l[?2004h>         f.write(f'Active Users: {active_users}\n')
[?2004l[?2004h>         f.write(f'Total Transactions: {total_transactions}\n')
[?2004l[?2004h>         f.write(f'Total Amount: {total_amount:.2f}\n')
[?2004l[?2004h>         f.write(f'Average per User: {avg_per_user:.2f}\n')
[?2004l[?2004h> 
[?2004l[?2004h> # Generate top users report
[?2004l[?2004h> def generate_top_users():
[?2004l[?2004h>     conn = psycopg2.connect(dbname='production_db', user='postgres', host='localhost')
[?2004l[?2004h>     cur = conn.cursor()
[?2004l[?2004h>     
[?2004l[?2004h>     cur.execute("""
[?2004l[?2004h>         SELECT u.username, COALESCE(SUM(t.amount), 0) as total_amount
[?2004l[?2004h>         FROM users u
[?2004l[?2004h>         LEFT JOIN transactions t ON u.user_id = t.user_id
[?2004l[?2004h>         GROUP BY u.username
[?2004l[?2004h>         ORDER BY total_amount DESC, u.username ASC
[?2004l[?2004h>         LIMIT 10
[?2004l[?2004h>     """)
[?2004l[?2004h>     
[?2004l[?2004h>     results = cur.fetchall()
[?2004l[?2004h>     cur.close()
[?2004l[?2004h>     conn.close()
[?2004l[?2004h>     
[?2004l[?2004h>     # Write top users
[?2004l[?2004h>     with open('/backup/top_users.csv', 'w', newline='') as f:
[?2004l[?2004h>         writer = csv.writer(f)
[?2004l[?2004h>         writer.writerow(['username', 'total_amount'])
[?2004l[?2004h>         for username, total_amount in results:
[?2004l[?2004h>             writer.writerow([username, f'{float(total_amount):.2f}'])
[?2004l[?2004h> 
[?2004l[?2004h> # Generate backup verification
[?2004l[?2004h> def generate_verification():
[?2004l[?2004h>     with open('/backup/backup_metadata.log', 'r') as f:
[?2004l[?2004h>         content = f.read()
[?2004l[?2004h>     
[?2004l[?2004h>     backup_date = ''
[?2004l[?2004h>     tables_backed_up = ''
[?2004l[?2004h>     total_rows = ''
[?2004l[?2004h>     integrity_check = ''
[?2004l[?2004h>     
[?2004l[?2004h>     for line in content.split('\n'):
[?2004l[?2004h>         if 'Backup timestamp:' in line:
[?2004l[?2004h>             backup_date = line.split('Backup timestamp:')[1].strip()
[?2004l[?2004h>         elif 'Total tables backed up:' in line:
[?2004l[?2004h>             tables_backed_up = line.split('Total tables backed up:')[1].strip()
[?2004l[?2004h>         elif 'Total rows backed up:' in line:
[?2004l[?2004h>             total_rows = line.split('Total rows backed up:')[1].strip()
[?2004l[?2004h>         elif 'Integrity check:' in line:
[?2004l[?2004h>             integrity_check = line.split('Integrity check:')[1].strip()
[?2004l[?2004h>     
[?2004l[?2004h>     with open('/backup/backup_verification.txt', 'w') as f:
[?2004l[?2004h>         f.write('BACKUP VERIFICATION\n')
[?2004l[?2004h>         f.write('===================\n')
[?2004l[?2004h>         f.write(f'Backup Date: {backup_date}\n')
[?2004l[?2004h>         f.write(f'Tables Backed Up: {tables_backed_up}\n')
[?2004l[?2004h>         f.write(f'Total Rows: {total_rows}\n')
[?2004l[?2004h>         f.write(f'Integrity Check: {integrity_check}\n')
[?2004l[?2004h> 
[?2004l[?2004h> # Main execution
[?2004l[?2004h> if __name__ == '__main__':
[?2004l[?2004h>     print('Creating database...')
[?2004l[?2004h>     create_database()
[?2004l[?2004h>     
[?2004l[?2004h>     print('Cleaning users data...')
[?2004l[?2004h>     users = clean_users()
[?2004l[?2004h>     
[?2004l[?2004h>     print('Cleaning transactions data...')
[?2004l[?2004h>     transactions = clean_transactions()
[?2004l[?2004h>     
[?2004l[?2004h>     print('Importing data...')
[?2004l[?2004h>     import_data(users, transactions)
[?2004l[?2004h>     
[?2004l[?2004h>     print('Generating statistics...')
[?2004l[?2004h>     generate_stats()
[?2004l[?2004h>     
[?2004l[?2004h>     print('Generating top users report...')
[?2004l[?2004h>     generate_top_users()
[?2004l[?2004h>     
[?2004l[?2004h>     print('Generating backup verification...')
[?2004l[?2004h>     generate_verification()
[?2004l[?2004h>     
[?2004l[?2004h>     print('Creating recovery completion marker...')
[?2004l[?2004h>     with open('/backup/recovery_complete.txt', 'w') as f:
[?2004l[?2004h>         f.write('RECOVERY_SUCCESSFUL\n')
[?2004l[?2004h>     
[?2004l[?2004h>     print('Recovery complete!')
[?2004l[?2004h> EOF
[?2004l[?2004hroot@76c15cab1a93:/backup# python3 /backup/restore_database.py; tmux wait -S done
[?2004lTraceback (most recent call last):
  File "/backup/restore_database.py", line 1, in <module>
    import psycopg2
ModuleNotFoundError: No module named 'psycopg2'
[?2004hroot@76c15cab1a93:/backup# pip3 install psycopg2-binary; tmux wait -S done
[?2004lbash: pip3: command not found
[?2004hroot@76c15cab1a93:/backup# python3 /backup/restore_database.py; tmux wait -S done
[?2004lTraceback (most recent call last):
  File "/backup/restore_database.py", line 1, in <module>
    import psycopg2
ModuleNotFoundError: No module named 'psycopg2'
[?2004hroot@76c15cab1a93:/backup# cat > /backup/restore_database.py << 'EOF'
[?2004l[?2004h> import subprocess
[?2004l[?2004h> import csv
[?2004l[?2004h> import json
[?2004l[?2004h> import re
[?2004l', cmd],
 [?2004h> import os
[?2004l[?2004h> 
[?2004l[?2004h> # Create database and restore schema
[?2004l[?2004h> def create_database():
[?2004l[?2004h>     # Drop and create database
[?2004l[?2004h>     subprocess.run(['psql', '-U', 'postgres', '-c', 'DROP DATABASE IF EXISTS production_db'], 
[?2004l[?2004h>                    env={**os.environ, 'PGHOST': 'localhost'})
[?2004lount,[?2004h>     subprocess.run(['psql', '-U', 'postgres', '-c', 'CREATE DATABASE production_db'], 
[?2004lmoun[?2004h>                    env={**os.environ, 'PGHOST': 'localhost'})
[?2004l[?2004h>     
[?2004l['psq[?2004h>     # Create users table
[?2004l[?2004h>     subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-c', '''
[?2004l[?2004h>         CREATE TABLE users (
[?2004l[?2004h>             user_id INTEGER PRIMARY KEY,
[?2004l database statistics
def generate_stats()[?2004h>             username VARCHAR(255) NOT NULL,
[?2004lPGHOST': 'localh[?2004h>             email VARCHAR(255) NOT NULL,
[?2004l[?2004h>             created_at TIMESTAMP,
[?2004l[?2004h>             status VARCHAR(50)
[?2004l[?2004h>         )
[?2004l '-t', '-c[?2004h>     '''], env={**os.environ, 'PGHOST': 'localhost'})
[?2004l[?2004h>     
[?2004l     [?2004h>     # Create transactions table
[?2004l[?2004h>     subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-c', '''
[?2004l[?2004h>         CREATE TABLE transactions (
[?2004l[?2004h>             transaction_id INTEGER PRIMARY KEY,
[?2004l[?2004h>             user_id INTEGER,
[?2004l[?2004h>             amount DECIMAL(10, 2),
[?2004l[?2004h>             timestamp TIMESTAMP,
[?2004l[?2004h>             description TEXT
[?2004l[?2004h>         )
[?2004l  a[?2004h>     '''], env={**os.environ, 'PGHOST': 'localhost'})
[?2004l[?2004h> 
[?2004l[?2004h> # Clean users data
[?2004l[?2004h> def clean_users():
[?2004l[?2004h>     valid_statuses = ['active', 'inactive', 'suspended']
[?2004lproduction_db', [?2004h>     email_pattern = re.compile(r'^[^@]+@[^@]+$')
[?2004l[?2004h>     
[?2004l[?2004h>     clean_data = []
[?2004l[?2004h>     with open('/backup/users_export.csv', 'r') as f:
[?2004l[?2004h>         reader = csv.DictReader(f)
[?2004l[?2004h>         for row in reader:
[?2004lm[?2004h>             # Check for missing user_id
[?2004l[?2004h>             if not row.get('user_id') or row['user_id'].strip() == '':
[?2004l[?2004h>                 continue
[?2004lra[?2004h>             
[?2004l[?2004h>             # Check for empty username
[?2004l[?2004h>             if not row.get('username') or row['username'].strip() == '':
[?2004l[?2004h>                 continue
[?2004l[?2004h>             
[?2004lf[?2004h>             # Check for invalid email
[?2004l[?2004h>             email = row.get('email', '').strip()
[?2004l[?2004h>             if not email or not email_pattern.match(email):
[?2004l[?2004h>                 continue
[?2004l [?2004h>             
[?2004lf:
        f.[?2004h>             # Check for invalid status
[?2004l[?2004h>             status = row.get('status', '').strip().lower()
[?2004l[?2004h>             if status not in valid_statuses:
[?2004l[?2004h>                 continue
[?2004l[?2004h>             
[?2004l[?2004h>             clean_data.append({
[?2004l[?2004h>                 'user_id': row['user_id'].strip(),
[?2004l[?2004h>                 'username': row['username'].strip(),
[?2004l[?2004h>                 'email': email,
[?2004l[?2004h>                 'created_at': row.get('created_at', '').strip(),
[?2004l[?2004h>                 'status': status
[?2004lhos[?2004h>             })
[?2004l[?2004h>     
[?2004l[?2004h>     # Write cleaned data
[?2004l[?2004h>     with open('/backup/clean_users.csv', 'w', newline='') as f:
[?2004l[?2004h>         writer = csv.DictWriter(f, fieldnames=['user_id', 'username', 'email', 'created_at', 'status'])
[?2004l[?2004h>         writer.writeheader()
[?2004l[?2004h>         writer.writerows(clean_data)
[?2004l[?2004h>     
[?2004l
    [?2004h>     return clean_data
[?2004l[?2004h> 
[?2004l[?2004h> # Clean transactions data
[?2004l[?2004h> def clean_transactions():
[?2004l[?2004h>     with open('/backup/transactions_backup.json', 'r') as f:
[?2004l lines = resu[?2004h>         transactions = json.load(f)
[?2004l[?2004h>     
[?2004l [?2004h>     valid_transactions = []
[?2004l[?2004h>     for txn in transactions:
[?2004l[?2004h>         # Check for null transaction_id
[?2004l'') as f:
        writer = cs[?2004h>         if txn.get('transaction_id') is None:
[?2004l[?2004h>             continue
[?2004l[?2004h>         
[?2004l, 'total_amount'])
        fo[?2004h>         # Check for null or negative amounts
[?2004l[?2004h>         amount = txn.get('amount')
[?2004l[?2004h>         if amount is None or amount <= 0:
[?2004l[?2004h>             continue
[?2004l2:
[?2004h>         
[?2004l[?2004h>         # Check for missing timestamp
[?2004l[?2004h>         if not txn.get('timestamp'):
[?2004l])[?2004h>             continue
[?2004l[?2004h>         
[?2004l[?2004h>         # Check for valid user_id (1-30)
[?2004l[?2004h>         user_id = txn.get('user_id')
[?2004l[?2004h>         if user_id is None or user_id < 1 or user_id > 30:
[?2004l[?2004h>             continue
[?2004l   [?2004h>         
[?2004l[?2004h>         valid_transactions.append(txn)
[?2004l[?2004h>     
[?2004l    t[?2004h>     # Write valid transactions
[?2004l  total_[?2004h>     with open('/backup/valid_transactions.json', 'w') as f:
[?2004l in cont[?2004h>         json.dump(valid_transactions, f, indent=2)
[?2004ln [?2004h>         f.write('\n')
[?2004l[?2004h>     
[?2004l[?2004h>     return valid_transactions
[?2004l[?2004h> 
[?2004l[?2004h> # Import data into database
[?2004l[?2004h> def import_data(users, transactions):
[?2004l[?2004h>     # Import users
[?2004l[?2004h>     for user in users:
[?2004llit('[?2004h>         cmd = f"INSERT INTO users (user_id, username, email, created_at, status) VALUES ({user['user_id']}, '{user['username']}', '{user['email']}', '{user['created_at']}', '{user['status']}')"
[?2004l[?2004h>         subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-c', cmd],
[?2004l[?2004h>                       env={**os.environ, 'PGHOST': 'localhost'})
[?2004l[?2004h>     
[?2004l([?2004h>     # Import transactions
[?2004l)
 [?2004h>     for txn in transactions:
[?2004l[?2004h>         desc = txn.get('description', '').replace("'", "''")
[?2004l[?2004h>         cmd = f"INSERT INTO transactions (transaction_id, user_id, amount, timestamp, description) VALUES ({txn['transaction_id']}, {txn['user_id']}, {txn['amount']}, '{txn['timestamp']}', '{desc}')"
[?2004l[?2004h>         subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-c', cmd],
[?2004lani[?2004h>                       env={**os.environ, 'PGHOST': 'localhost'})
[?2004l[?2004h> 
[?2004ln[?2004h> # Generate database statistics
[?2004l
    [?2004h> def generate_stats():
[?2004l[?2004h>     env = {**os.environ, 'PGHOST': 'localhost'}
[?2004l'[?2004h>     
[?2004l)
   [?2004h>     # Total users
[?2004lrs[?2004h>     result = subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-t', '-c', 'SELECT COUNT(*) FROM users'],
[?2004l[?2004h>                            capture_output=True, text=True, env=env)
[?2004l[?2004h>     total_users = int(result.stdout.strip())
[?2004lication()
[?2004h>     
[?2004l
[?2004h>     # Active users
[?2004lg[?2004h>     result = subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-t', '-c', "SELECT COUNT(*) FROM users WHERE status = 'active'"],
[?2004l[?2004h>                            capture_output=True, text=True, env=env)
[?2004l[?2004h>     active_users = int(result.stdout.strip())
[?2004l[?2004h>     
[?2004l[?2004h>     # Total transactions
[?2004l[?2004h>     result = subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-t', '-c', 'SELECT COUNT(*) FROM transactions'],
[?2004l[?2004h>                            capture_output=True, text=True, env=env)
[?2004l[?2004h>     total_transactions = int(result.stdout.strip())
[?2004l[?2004h>     
[?2004l[?2004h>     # Total amount
[?2004l[?2004h>     result = subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-t', '-c', 'SELECT COALESCE(SUM(amount), 0) FROM transactions'],
[?2004l[?2004h>                            capture_output=True, text=True, env=env)
[?2004l[?2004h>     total_amount = float(result.stdout.strip())
[?2004l[?2004h>     
[?2004l[?2004h>     # Average per user
[?2004l[?2004h>     if total_users > 0:
[?2004l[?2004h>         avg_per_user = total_amount / total_users
[?2004l[?2004h>     else:
[?2004l[?2004h>         avg_per_user = 0
[?2004l[?2004h>     
[?2004l[?2004h>     # Write stats
[?2004l[?2004h>     with open('/backup/db_stats.txt', 'w') as f:
[?2004l[?2004h>         f.write('DATABASE STATISTICS\n')
[?2004l[?2004h>         f.write('==================\n')
[?2004l[?2004h>         f.write(f'Total Users: {total_users}\n')
[?2004l[?2004h>         f.write(f'Active Users: {active_users}\n')
[?2004l[?2004h>         f.write(f'Total Transactions: {total_transactions}\n')
[?2004l[?2004h>         f.write(f'Total Amount: {total_amount:.2f}\n')
[?2004l[?2004h>         f.write(f'Average per User: {avg_per_user:.2f}\n')
[?2004l[?2004h> 
[?2004l[?2004h> # Generate top users report
[?2004l[?2004h> def generate_top_users():
[?2004l[?2004h>     env = {**os.environ, 'PGHOST': 'localhost'}
[?2004l[?2004h>     
[?2004l[?2004h>     result = subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-t', '-c', '''
[?2004l[?2004h>         SELECT u.username, COALESCE(SUM(t.amount), 0) as total_amount
[?2004l[?2004h>         FROM users u
[?2004l[?2004h>         LEFT JOIN transactions t ON u.user_id = t.user_id
[?2004l[?2004h>         GROUP BY u.username
[?2004l[?2004h>         ORDER BY total_amount DESC, u.username ASC
[?2004l[?2004h>         LIMIT 10
[?2004l[?2004h>     '''], capture_output=True, text=True, env=env)
[?2004l[?2004h>     
[?2004l[?2004h>     lines = result.stdout.strip().split('\n')
[?2004l[?2004h>     
[?2004l[?2004h>     # Write top users
[?2004l[?2004h>     with open('/backup/top_users.csv', 'w', newline='') as f:
[?2004l[?2004h>         writer = csv.writer(f)
[?2004l[?2004h>         writer.writerow(['username', 'total_amount'])
[?2004l[?2004h>         for line in lines:
[?2004l[?2004h>             if line.strip():
[?2004l[?2004h>                 parts = [p.strip() for p in line.split('|')]
[?2004l[?2004h>                 if len(parts) == 2:
[?2004l[?2004h>                     username = parts[0]
[?2004l[?2004h>                     amount = float(parts[1])
[?2004l[?2004h>                     writer.writerow([username, f'{amount:.2f}'])
[?2004l[?2004h> 
[?2004l[?2004h> # Generate backup verification
[?2004l[?2004h> def generate_verification():
[?2004l[?2004h>     with open('/backup/backup_metadata.log', 'r') as f:
[?2004l[?2004h>         content = f.read()
[?2004l[?2004h>     
[?2004l[?2004h>     backup_date = ''
[?2004l[?2004h>     tables_backed_up = ''
[?2004l[?2004h>     total_rows = ''
[?2004l[?2004h>     integrity_check = ''
[?2004l[?2004h>     
[?2004l[?2004h>     for line in content.split('\n'):
[?2004l[?2004h>         if 'Backup timestamp:' in line:
[?2004l[?2004h>             backup_date = line.split('Backup timestamp:')[1].strip()
[?2004l[?2004h>         elif 'Total tables backed up:' in line:
[?2004l[?2004h>             tables_backed_up = line.split('Total tables backed up:')[1].strip()
[?2004l[?2004h>         elif 'Total rows backed up:' in line:
[?2004l[?2004h>             total_rows = line.split('Total rows backed up:')[1].strip()
[?2004l[?2004h>         elif 'Integrity check:' in line:
[?2004l[?2004h>             integrity_check = line.split('Integrity check:')[1].strip()
[?2004l[?2004h>     
[?2004l[?2004h>     with open('/backup/backup_verification.txt', 'w') as f:
[?2004l[?2004h>         f.write('BACKUP VERIFICATION\n')
[?2004l[?2004h>         f.write('===================\n')
[?2004l[?2004h>         f.write(f'Backup Date: {backup_date}\n')
[?2004l[?2004h>         f.write(f'Tables Backed Up: {tables_backed_up}\n')
[?2004l[?2004h>         f.write(f'Total Rows: {total_rows}\n')
[?2004l[?2004h>         f.write(f'Integrity Check: {integrity_check}\n')
[?2004l[?2004h> 
[?2004l[?2004h> # Main execution
[?2004l[?2004h> if __name__ == '__main__':
[?2004l[?2004h>     print('Creating database...')
[?2004l[?2004h>     create_database()
[?2004l[?2004h>     
[?2004l[?2004h>     print('Cleaning users data...')
[?2004l[?2004h>     users = clean_users()
[?2004l[?2004h>     
[?2004l[?2004h>     print('Cleaning transactions data...')
[?2004l[?2004h>     transactions = clean_transactions()
[?2004l[?2004h>     
[?2004l[?2004h>     print('Importing data...')
[?2004l[?2004h>     import_data(users, transactions)
[?2004l[?2004h>     
[?2004l[?2004h>     print('Generating statistics...')
[?2004l[?2004h>     generate_stats()
[?2004l[?2004h>     
[?2004l[?2004h>     print('Generating top users report...')
[?2004l[?2004h>     generate_top_users()
[?2004l[?2004h>     
[?2004l[?2004h>     print('Generating backup verification...')
[?2004l[?2004h>     generate_verification()
[?2004l[?2004h>     
[?2004l[?2004h>     print('Creating recovery completion marker...')
[?2004l[?2004h>     with open('/backup/recovery_complete.txt', 'w') as f:
[?2004l[?2004h>         f.write('RECOVERY_SUCCESSFUL\n')
[?2004l[?2004h>     
[?2004l[?2004h>     print('Recovery complete!')
[?2004l[?2004h> EOF
[?2004l[?2004hroot@76c15cab1a93:/backup# python3 /backup/restore_database.py; tmux wait -S done
[?2004lCreating database...
Password for user postgres: Traceback (most recent call last):
  File "/backup/restore_database.py", line 227, in <module>
    create_database()
  File "/backup/restore_database.py", line 10, in create_database
    subprocess.run(['psql', '-U', 'postgres', '-c', 'DROP DATABASE IF EXISTS production_db'], 
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/subprocess.py", line 550, in run
    stdout, stderr = process.communicate(input, timeout=timeout)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/subprocess.py", line 1201, in communicate
    self.wait()
  File "/usr/lib/python3.12/subprocess.py", line 1264, in wait
    return self._wait(timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/subprocess.py", line 2053, in _wait
    (pid, sts) = self._try_wait(0)
                 ^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/subprocess.py", line 2011, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

[?2004hroot@76c15cab1a93:/backup# sed -i 's/peer/trust/g' /etc/postgresql/*/main/pg_hba.conf; tmux wait -S done
[?2004l[?2004hroot@76c15cab1a93:/backup# sed -i 's/md5/trust/g' /etc/postgresql/*/main/pg_hba.conf; tmux wait -S done
[?2004l[?2004hroot@76c15cab1a93:/backup# service postgresql restart; tmux wait -S done
[?2004l * Restarting PostgreSQL 16 database server       [160G [154G[ OK ]
[?2004hroot@76c15cab1a93:/backup# python3 /backup/restore_database.py; tmux wait -S done
[?2004lCreating database...
Password for user postgres: Traceback (most recent call last):
  File "/backup/restore_database.py", line 227, in <module>
    create_database()
  File "/backup/restore_database.py", line 10, in create_database
    subprocess.run(['psql', '-U', 'postgres', '-c', 'DROP DATABASE IF EXISTS production_db'], 
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/subprocess.py", line 550, in run
    stdout, stderr = process.communicate(input, timeout=timeout)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/subprocess.py", line 1201, in communicate
    self.wait()
  File "/usr/lib/python3.12/subprocess.py", line 1264, in wait
    return self._wait(timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/subprocess.py", line 2053, in _wait
    (pid, sts) = self._try_wait(0)
                 ^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/subprocess.py", line 2011, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

[?2004hroot@76c15cab1a93:/backup# cat /etc/postgresql/*/main/pg_hba.conf | grep -v '^#' | grep -v '^$'; tmux wait -S done
[?2004llocal   all             postgres                                trust
local   all             all                                     trust
host    all             all             127.0.0.1/32            scram-sha-256
host    all             all             ::1/128                 scram-sha-256
local   replication     all                                     trust
host    replication     all             127.0.0.1/32            scram-sha-256
host    replication     all             ::1/128                 scram-sha-256
[?2004hroot@76c15cab1a93:/backup# sed -i 's/scram-sha-256/trust/g' /etc/postgresql/*/main/pg_hba.conf; tmux wait -S done
[?2004l[?2004hroot@76c15cab1a93:/backup# service postgresql restart; tmux wait -S done
[?2004l * Restarting PostgreSQL 16 database server       [160G [154G[ OK ]
[?2004hroot@76c15cab1a93:/backup# python3 /backup/restore_database.py; tmux wait -S done
[?2004lCreating database...
NOTICE:  database "production_db" does not exist, skipping
DROP DATABASE
CREATE DATABASE
CREATE TABLE
CREATE TABLE
Cleaning users data...
Cleaning transactions data...
Traceback (most recent call last):
  File "/backup/restore_database.py", line 233, in <module>
    transactions = clean_transactions()
                   ^^^^^^^^^^^^^^^^^^^^
  File "/backup/restore_database.py", line 93, in clean_transactions
    if amount is None or amount <= 0:
                         ^^^^^^^^^^^
TypeError: '<=' not supported between instances of 'str' and 'int'
[?2004hroot@76c15cab1a93:/backup# cat > /backup/restore_database.py << 'EOF'
[?2004l[?2004h> import subprocess
[?2004l[?2004h> import csv
[?2004l\n')
    
    return valid_tr[?2004h> import json
[?2004l[?2004h> import re
[?2004l[?2004h> import os
[?2004l[?2004h> 
[?2004l[?2004h> # Create database and restore schema
[?2004l[?2004h> def create_database():
[?2004l[?2004h>     # Drop and create database
[?2004l[?2004h>     subprocess.run(['psql', '-U', 'postgres', '-c', 'DROP DATABASE IF EXISTS production_db'], 
[?2004l[?2004h>                    env={**os.environ, 'PGHOST': 'localhost'})
[?2004l[?2004h>     subprocess.run(['psql', '-U', 'postgres', '-c', 'CREATE DATABASE production_db'], 
[?2004l[?2004h>                    env={**os.environ, 'PGHOST': 'localhost'})
[?2004l[?2004h>     
[?2004l[?2004h>     # Create users table
[?2004l[?2004h>     subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-c', '''
[?2004l[?2004h>         CREATE TABLE users (
[?2004lt([?2004h>             user_id INTEGER PRIMARY KEY,
[?2004l[?2004h>             username VARCHAR(255) NOT NULL,
[?2004l[?2004h>             email VARCHAR(255) NOT NULL,
[?2004l[?2004h>             created_at TIMESTAMP,
[?2004l[?2004h>             status VARCHAR(50)
[?2004l, {txn['user_id']}, {tx[?2004h>         )
[?2004lunt'[?2004h>     '''], env={**os.environ, 'PGHOST': 'localhost'})
[?2004l[?2004h>     
[?2004l[?2004h>     # Create transactions table
[?2004l[?2004h>     subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-c', '''
[?2004lOS[?2004h>         CREATE TABLE transactions (
[?2004lu[?2004h>             transaction_id INTEGER PRIMARY KEY,
[?2004l[?2004h>             user_id INTEGER,
[?2004l[?2004h>             amount DECIMAL(10, 2),
[?2004l[?2004h>             timestamp TIMESTAMP,
[?2004l[?2004h>             description TEXT
[?2004l[?2004h>         )
[?2004l[?2004h>     '''], env={**os.environ, 'PGHOST': 'localhost'})
[?2004l[?2004h> 
[?2004l[?2004h> # Clean users data
[?2004l[?2004h> def clean_users():
[?2004l[?2004h>     valid_statuses = ['active', 'inactive', 'suspended']
[?2004l[?2004h>     email_pattern = re.compile(r'^[^@]+@[^@]+$')
[?2004l[?2004h>     
[?2004l[?2004h>     clean_data = []
[?2004l[?2004h>     with open('/backup/users_export.csv', 'r') as f:
[?2004l[?2004h>         reader = csv.DictReader(f)
[?2004l[?2004h>         for row in reader:
[?2004l[?2004h>             # Check for missing user_id
[?2004l[?2004h>             if not row.get('user_id') or row['user_id'].strip() == '':
[?2004l[?2004h>                 continue
[?2004l[?2004h>             
[?2004l[?2004h>             # Check for empty username
[?2004l[?2004h>             if not row.get('username') or row['username'].strip() == '':
[?2004l F[?2004h>                 continue
[?2004l[?2004h>             
[?2004l[?2004h>             # Check for invalid email
[?2004l[?2004h>             email = row.get('email', '').strip()
[?2004l[?2004h>             if not email or not email_pattern.match(email):
[?2004l
    result = subproce[?2004h>                 continue
[?2004l[?2004h>             
[?2004l[?2004h>             # Check for invalid status
[?2004l[?2004h>             status = row.get('status', '').strip().lower()
[?2004lamount), 0) FROM transactions'],
             [?2004h>             if status not in valid_statuses:
[?2004l[?2004h>                 continue
[?2004l[?2004h>             
[?2004l[?2004h>             clean_data.append({
[?2004l[?2004h>                 'user_id': row['user_id'].strip(),
[?2004l[?2004h>                 'username': row['username'].strip(),
[?2004l[?2004h>                 'email': email,
[?2004l# [?2004h>                 'created_at': row.get('created_at', '').strip(),
[?2004l[?2004h>                 'status': status
[?2004l[?2004h>             })
[?2004l[?2004h>     
[?2004l[?2004h>     # Write cleaned data
[?2004l[?2004h>     with open('/backup/clean_users.csv', 'w', newline='') as f:
[?2004l        f.write([?2004h>         writer = csv.DictWriter(f, fieldnames=['user_id', 'username', 'email', 'created_at', 'status'])
[?2004l[?2004h>         writer.writeheader()
[?2004l[?2004h>         writer.writerows(clean_data)
[?2004lwrite(f[?2004h>     
[?2004l[?2004h>     return clean_data
[?2004ler[?2004h> 
[?2004l[?2004h> # Clean transactions data
[?2004l[?2004h> def clean_transactions():
[?2004l[?2004h>     with open('/backup/transactions_backup.json', 'r') as f:
[?2004l[?2004h>         transactions = json.load(f)
[?2004l[?2004h>     
[?2004l[?2004h>     valid_transactions = []
[?2004l[?2004h>     for txn in transactions:
[?2004lc',[?2004h>         # Check for null transaction_id
[?2004l[?2004h>         if txn.get('transaction_id') is None:
[?2004l[?2004h>             continue
[?2004l[?2004h>         
[?2004l[?2004h>         # Check for null or negative amounts
[?2004l    [?2004h>         amount = txn.get('amount')
[?2004lR [?2004h>         if amount is None:
[?2004l[?2004h>             continue
[?2004lM[?2004h>         
[?2004l[?2004h>         # Convert to float if it's a string
[?2004l[?2004h>         try:
[?2004l    [?2004h>             amount_val = float(amount)
[?2004l[?2004h>         except (ValueError, TypeError):
[?2004l[?2004h>             continue
[?2004l_user[?2004h>         
[?2004ls.csv', '[?2004h>         if amount_val <= 0:
[?2004l[?2004h>             continue
[?2004lw', newline='') as f:
        writer = csv.writer[?2004h>         
[?2004l[?2004h>         # Check for missing timestamp
[?2004l[?2004h>         if not txn.get('timestamp'):
[?2004l[?2004h>             continue
[?2004l[?2004h>         
[?2004l[?2004h>         # Check for valid user_id (1-30)
[?2004l[?2004h>         user_id = txn.get('user_id')
[?2004l i[?2004h>         if user_id is None:
[?2004l[?2004h>             continue
[?2004l[?2004h>         
[?2004lts[0][?2004h>         try:
[?2004l[?2004h>             user_id_val = int(user_id)
[?2004l[?2004h>         except (ValueError, TypeError):
[?2004l[?2004h>             continue
[?2004l[?2004h>         
[?2004l Generate[?2004h>         if user_id_val < 1 or user_id_val > 30:
[?2004le_verification()[?2004h>             continue
[?2004l:
    with open('/bac[?2004h>         
[?2004l[?2004h>         valid_transactions.append(txn)
[?2004l      con[?2004h>     
[?2004ltent [?2004h>     # Write valid transactions
[?2004l[?2004h>     with open('/backup/valid_transactions.json', 'w') as f:
[?2004l[?2004h>         json.dump(valid_transactions, f, indent=2)
[?2004l[?2004h>         f.write('\n')
[?2004l[?2004h>     
[?2004l[?2004h>     return valid_transactions
[?2004l[?2004h> 
[?2004ltamp:' in line:
          [?2004h> # Import data into database
[?2004l[?2004h> def import_data(users, transactions):
[?2004l[?2004h>     # Import users
[?2004lables[?2004h>     for user in users:
[?2004l[?2004h>         cmd = f"INSERT INTO users (user_id, username, email, created_at, status) VALUES ({user['user_id']}, '{user['username']}', '{user['email']}', '{user['created_at']}', '{user['status']}')"
[?2004l[?2004h>         subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-c', cmd],
[?2004l[?2004h>                       env={**os.environ, 'PGHOST': 'localhost'}, capture_output=True)
[?2004lwith open('/backup/backup_verification.txt', '[?2004h>     
[?2004lw') a[?2004h>     # Import transactions
[?2004ls f:
        f.write('BACK[?2004h>     for txn in transactions:
[?2004l[?2004h>         desc = txn.get('description', '').replace("'", "''")
[?2004lDate[?2004h>         cmd = f"INSERT INTO transactions (transaction_id, user_id, amount, timestamp, description) VALUES ({txn['transaction_id']}, {txn['user_id']}, {txn['amount']}, '{txn['timestamp']}', '{desc}')"
[?2004l[?2004h>         subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-c', cmd],
[?2004l[?2004h>                       env={**os.environ, 'PGHOST': 'localhost'}, capture_output=True)
[?2004l[?2004h> 
[?2004ln[?2004h> # Generate database statistics
[?2004l   [?2004h> def generate_stats():
[?2004lean_t[?2004h>     env = {**os.environ, 'PGHOST': 'localhost'}
[?2004lorting data...'[?2004h>     
[?2004l[?2004h>     # Total users
[?2004lusers[?2004h>     result = subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-t', '-c', 'SELECT COUNT(*) FROM users'],
[?2004l[?2004h>                            capture_output=True, text=True, env=env)
[?2004l[?2004h>     total_users = int(result.stdout.strip())
[?2004l[?2004h>     
[?2004l[?2004h>     # Active users
[?2004l[?2004h>     result = subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-t', '-c', "SELECT COUNT(*) FROM users WHERE status = 'active'"],
[?2004l[?2004h>                            capture_output=True, text=True, env=env)
[?2004l)
EOF
[?2004h>     active_users = int(result.stdout.strip())
[?2004l[?2004h>     
[?2004l[?2004h>     # Total transactions
[?2004l[?2004h>     result = subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-t', '-c', 'SELECT COUNT(*) FROM transactions'],
[?2004l[?2004h>                            capture_output=True, text=True, env=env)
[?2004l[?2004h>     total_transactions = int(result.stdout.strip())
[?2004l[?2004h>     
[?2004l[?2004h>     # Total amount
[?2004l[?2004h>     result = subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-t', '-c', 'SELECT COALESCE(SUM(amount), 0) FROM transactions'],
[?2004l[?2004h>                            capture_output=True, text=True, env=env)
[?2004l[?2004h>     total_amount = float(result.stdout.strip())
[?2004l[?2004h>     
[?2004l[?2004h>     # Average per user
[?2004l[?2004h>     if total_users > 0:
[?2004l[?2004h>         avg_per_user = total_amount / total_users
[?2004l[?2004h>     else:
[?2004l[?2004h>         avg_per_user = 0
[?2004l[?2004h>     
[?2004l[?2004h>     # Write stats
[?2004l[?2004h>     with open('/backup/db_stats.txt', 'w') as f:
[?2004l[?2004h>         f.write('DATABASE STATISTICS\n')
[?2004l[?2004h>         f.write('==================\n')
[?2004l[?2004h>         f.write(f'Total Users: {total_users}\n')
[?2004l[?2004h>         f.write(f'Active Users: {active_users}\n')
[?2004l[?2004h>         f.write(f'Total Transactions: {total_transactions}\n')
[?2004l[?2004h>         f.write(f'Total Amount: {total_amount:.2f}\n')
[?2004l[?2004h>         f.write(f'Average per User: {avg_per_user:.2f}\n')
[?2004l[?2004h> 
[?2004l[?2004h> # Generate top users report
[?2004l[?2004h> def generate_top_users():
[?2004l[?2004h>     env = {**os.environ, 'PGHOST': 'localhost'}
[?2004l[?2004h>     
[?2004l[?2004h>     result = subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-t', '-c', '''
[?2004l[?2004h>         SELECT u.username, COALESCE(SUM(t.amount), 0) as total_amount
[?2004l[?2004h>         FROM users u
[?2004l[?2004h>         LEFT JOIN transactions t ON u.user_id = t.user_id
[?2004l[?2004h>         GROUP BY u.username
[?2004l[?2004h>         ORDER BY total_amount DESC, u.username ASC
[?2004l[?2004h>         LIMIT 10
[?2004l[?2004h>     '''], capture_output=True, text=True, env=env)
[?2004l[?2004h>     
[?2004l[?2004h>     lines = result.stdout.strip().split('\n')
[?2004l[?2004h>     
[?2004l[?2004h>     # Write top users
[?2004l[?2004h>     with open('/backup/top_users.csv', 'w', newline='') as f:
[?2004l[?2004h>         writer = csv.writer(f)
[?2004l[?2004h>         writer.writerow(['username', 'total_amount'])
[?2004l[?2004h>         for line in lines:
[?2004l[?2004h>             if line.strip():
[?2004l[?2004h>                 parts = [p.strip() for p in line.split('|')]
[?2004l[?2004h>                 if len(parts) == 2:
[?2004l[?2004h>                     username = parts[0]
[?2004l[?2004h>                     amount = float(parts[1])
[?2004l[?2004h>                     writer.writerow([username, f'{amount:.2f}'])
[?2004l[?2004h> 
[?2004l[?2004h> # Generate backup verification
[?2004l[?2004h> def generate_verification():
[?2004l[?2004h>     with open('/backup/backup_metadata.log', 'r') as f:
[?2004l[?2004h>         content = f.read()
[?2004l[?2004h>     
[?2004l[?2004h>     backup_date = ''
[?2004l[?2004h>     tables_backed_up = ''
[?2004l[?2004h>     total_rows = ''
[?2004l[?2004h>     integrity_check = ''
[?2004l[?2004h>     
[?2004l[?2004h>     for line in content.split('\n'):
[?2004l[?2004h>         if 'Backup timestamp:' in line:
[?2004l[?2004h>             backup_date = line.split('Backup timestamp:')[1].strip()
[?2004l[?2004h>         elif 'Total tables backed up:' in line:
[?2004l[?2004h>             tables_backed_up = line.split('Total tables backed up:')[1].strip()
[?2004l[?2004h>         elif 'Total rows backed up:' in line:
[?2004l[?2004h>             total_rows = line.split('Total rows backed up:')[1].strip()
[?2004l[?2004h>         elif 'Integrity check:' in line:
[?2004l[?2004h>             integrity_check = line.split('Integrity check:')[1].strip()
[?2004l[?2004h>     
[?2004l[?2004h>     with open('/backup/backup_verification.txt', 'w') as f:
[?2004l[?2004h>         f.write('BACKUP VERIFICATION\n')
[?2004l[?2004h>         f.write('===================\n')
[?2004l[?2004h>         f.write(f'Backup Date: {backup_date}\n')
[?2004l[?2004h>         f.write(f'Tables Backed Up: {tables_backed_up}\n')
[?2004l[?2004h>         f.write(f'Total Rows: {total_rows}\n')
[?2004l[?2004h>         f.write(f'Integrity Check: {integrity_check}\n')
[?2004l[?2004h> 
[?2004l[?2004h> # Main execution
[?2004l[?2004h> if __name__ == '__main__':
[?2004l[?2004h>     print('Creating database...')
[?2004l[?2004h>     create_database()
[?2004l[?2004h>     
[?2004l[?2004h>     print('Cleaning users data...')
[?2004l[?2004h>     users = clean_users()
[?2004l[?2004h>     
[?2004l[?2004h>     print('Cleaning transactions data...')
[?2004l[?2004h>     transactions = clean_transactions()
[?2004l[?2004h>     
[?2004l[?2004h>     print('Importing data...')
[?2004l[?2004h>     import_data(users, transactions)
[?2004l[?2004h>     
[?2004l[?2004h>     print('Generating statistics...')
[?2004l[?2004h>     generate_stats()
[?2004l[?2004h>     
[?2004l[?2004h>     print('Generating top users report...')
[?2004l[?2004h>     generate_top_users()
[?2004l[?2004h>     
[?2004l[?2004h>     print('Generating backup verification...')
[?2004l[?2004h>     generate_verification()
[?2004l[?2004h>     
[?2004l[?2004h>     print('Creating recovery completion marker...')
[?2004l[?2004h>     with open('/backup/recovery_complete.txt', 'w') as f:
[?2004l[?2004h>         f.write('RECOVERY_SUCCESSFUL\n')
[?2004l[?2004h>     
[?2004l[?2004h>     print('Recovery complete!')
[?2004l[?2004h> EOF
[?2004l[?2004hroot@76c15cab1a93:/backup# python3 /backup/restore_database.py; tmux wait -S done
[?2004lCreating database...
DROP DATABASE
CREATE DATABASE
CREATE TABLE
CREATE TABLE
Cleaning users data...
Cleaning transactions data...
Importing data...
Generating statistics...
Generating top users report...
Generating backup verification...
Creating recovery completion marker...
Recovery complete!
[?2004hroot@76c15cab1a93:/backup# ls -la /backup/*.csv /backup/*.json /backup/*.txt 2>/dev/null; tmux wait -S done
[?2004l-rw-r--r-- 1 root root   133 Dec  4 19:08 /backup/backup_verification.txt
-rw-r--r-- 1 root root  2052 Dec  4 19:08 /backup/clean_users.csv
-rw-r--r-- 1 root root   145 Dec  4 19:08 /backup/db_stats.txt
-rw-r--r-- 1 root root    20 Dec  4 19:08 /backup/recovery_complete.txt
-rw-r--r-- 1 root root   230 Dec  4 19:08 /backup/top_users.csv
-rw-r--r-- 1 root root 15425 Dec  4 16:54 /backup/transactions_backup.json
-rw-r--r-- 1 root root  2351 Dec  4 16:54 /backup/users_export.csv
-rw-r--r-- 1 root root 14573 Dec  4 19:08 /backup/valid_transactions.json
[?2004hroot@76c15cab1a93:/backup# echo '=== clean_users.csv ==='; tmux wait -S done
[?2004l=== clean_users.csv ===
[?2004hroot@76c15cab1a93:/backup# head -5 /backup/clean_users.csv; tmux wait -S done
[?2004luser_id,username,email,created_at,status
1,alice_smith,alice_smith@example.com,2024-11-21 01:25:46,inactive
2,bob_jones,bob_jones@example.com,2025-06-28 01:25:46,active
3,charlie_brown,charlie_brown@example.com,2025-08-13 01:25:46,suspended
4,diana_prince,diana_prince@example.com,2025-08-05 01:25:46,inactive
[?2004hroot@76c15cab1a93:/backup# echo '=== valid_transactions.json ==='; tmux wait -S done
[?2004l=== valid_transactions.json ===
[?2004hroot@76c15cab1a93:/backup# head -20 /backup/valid_transactions.json; tmux wait -S done
[?2004l[
  {
    "transaction_id": 1,
    "user_id": 16,
    "amount": 46.0,
    "timestamp": "2025-07-16 01:25:56",
    "description": "Subscription"
  },
  {
    "transaction_id": 2,
    "user_id": 6,
    "amount": 646.05,
    "timestamp": "2025-05-02 01:25:56",
    "description": "Payment"
  },
  {
    "transaction_id": 3,
    "user_id": 29,
    "amount": 186.76,
    "timestamp": "2025-07-30 01:25:56",
[?2004hroot@76c15cab1a93:/backup# echo '=== db_stats.txt ==='; tmux wait -S done
[?2004l=== db_stats.txt ===
[?2004hroot@76c15cab1a93:/backup# cat /backup/db_stats.txt; tmux wait -S done
[?2004lDATABASE STATISTICS
==================
Total Users: 30
Active Users: 13
Total Transactions: 100
Total Amount: 53109.46
Average per User: 1770.32
[?2004hroot@76c15cab1a93:/backup# echo '=== top_users.csv ==='; tmux wait -S done
[?2004l=== top_users.csv ===
[?2004hroot@76c15cab1a93:/backup# cat /backup/top_users.csv; tmux wait -S done
[?2004lusername,total_amount
zara_ahmed,4400.17
alice_smith,3682.87
victor_von,3451.21
donna_noble,3225.49
xavier_prof,2990.51
nick_fury,2709.20
wade_wilson,2678.95
tony_stark,2637.00
frank_white,2539.97
charlie_brown,2525.32
[?2004hroot@76c15cab1a93:/backup# echo '=== backup_verification.txt ==='; tmux wait -S done
[?2004l=== backup_verification.txt ===
[?2004hroot@76c15cab1a93:/backup# cat /backup/backup_verification.txt; tmux wait -S done
[?2004lBACKUP VERIFICATION
===================
Backup Date: 2025-09-28 03:00:00
Tables Backed Up: 2
Total Rows: 130
Integrity Check: PASSED
[?2004hroot@76c15cab1a93:/backup# echo '=== recovery_complete.txt ==='; tmux wait -S done
[?2004l=== recovery_complete.txt ===
[?2004hroot@76c15cab1a93:/backup# cat /backup/recovery_complete.txt; tmux wait -S done
[?2004lRECOVERY_SUCCESSFUL
[?2004hroot@76c15cab1a93:/backup# psql -U postgres -d production_db -c '\dt'; tmux wait -S done
[?2004l            List of relations
 Schema |     Name     | Type  |  Owner   
--------+--------------+-------+----------
 public | transactions | table | postgres
 public | users        | table | postgres
(2 rows)

[?2004hroot@76c15cab1a93:/backup# psql -U postgres -d production_db -c 'SELECT COUNT(*) FROM users;'; tmux wait -S done
[?2004l count 
-------
    30
(1 row)

[?2004hroot@76c15cab1a93:/backup# psql -U postgres -d production_db -c 'SELECT COUNT(*) FROM transactions;'; tmux wait -S done
[?2004l count 
-------
   100
(1 row)

[?2004hroot@76c15cab1a93:/backup# wc -l /backup/clean_users.csv; tmux wait -S done
[?2004l31 /backup/clean_users.csv
[?2004hroot@76c15cab1a93:/backup# head -3 /backup/clean_users.csv; tmux wait -S done
[?2004luser_id,username,email,created_at,status
1,alice_smith,alice_smith@example.com,2024-11-21 01:25:46,inactive
2,bob_jones,bob_jones@example.com,2025-06-28 01:25:46,active
[?2004hroot@76c15cab1a93:/backup# tail -1 /backup/clean_users.csv | od -c | head -2; tmux wait -S done
[?2004l0000000   3   0   ,   d   o   n   n   a   _   n   o   b   l   e   ,   d
0000020   o   n   n   a   _   n   o   b   l   e   @   e   x   a   m   p
[?2004hroot@76c15cab1a93:/backup# wc -l /backup/valid_transactions.json; tmux wait -S done
[?2004l702 /backup/valid_transactions.json
[?2004hroot@76c15cab1a93:/backup# tail -3 /backup/valid_transactions.json; tmux wait -S done
[?2004l    "description": "Subscription"
  }
]
[?2004hroot@76c15cab1a93:/backup# for file in /backup/clean_users.csv /backup/valid_transactions.json /backup/db_stats.txt /backup/top_users.csv /backup/backup_verification.txt /backup/recovery_complete.txt; do echo "=== $file ==="  && tail -c 1 "$file" | od -An -tx1; done; tmux wait -S done
[?2004l=== /backup/clean_users.csv ===
 0a
=== /backup/valid_transactions.json ===
 0a
=== /backup/db_stats.txt ===
 0a
=== /backup/top_users.csv ===
 0a
=== /backup/backup_verification.txt ===
 0a
=== /backup/recovery_complete.txt ===
 0a
[?2004hroot@76c15cab1a93:/backup# echo 'All files verified!'; tmux wait -S done
[?2004lAll files verified!
[?2004hroot@76c15cab1a93:/backup# wc -l /backup/top_users.csv; tmux wait -S done
[?2004l11 /backup/top_users.csv
[?2004hroot@76c15cab1a93:/backup# cat /backup/top_users.csv; tmux wait -S done
[?2004lusername,total_amount
zara_ahmed,4400.17
alice_smith,3682.87
victor_von,3451.21
donna_noble,3225.49
xavier_prof,2990.51
nick_fury,2709.20
wade_wilson,2678.95
tony_stark,2637.00
frank_white,2539.97
charlie_brown,2525.32
[?2004hroot@76c15cab1a93:/backup# echo '=== Verifying database can be queried ==='; tmux wait -S done
[?2004l=== Verifying database can be queried ===
[?2004hroot@76c15cab1a93:/backup# psql -U postgres -d production_db -c "SELECT username, email, status FROM users LIMIT 3;"; tmux wait -S done
[?2004l   username    |           email           |  status   
---------------+---------------------------+-----------
 alice_smith   | alice_smith@example.com   | inactive
 bob_jones     | bob_jones@example.com     | active
 charlie_brown | charlie_brown@example.com | suspended
(3 rows)

[?2004hroot@76c15cab1a93:/backup# psql -U postgres -d production_db -c "SELECT transaction_id, user_id, amount FROM transactions LIMIT 3;"; tmux wait -S done
[?2004l transaction_id | user_id | amount 
----------------+---------+--------
              1 |      16 |  46.00
              2 |       6 | 646.05
              3 |      29 | 186.76
(3 rows)

[?2004hroot@76c15cab1a93:/backup# echo '=== All tasks completed successfully! ==='; tmux wait -S done
[?2004l=== All tasks completed successfully! ===
[?2004hroot@76c15cab1a93:/backup# [?2004l
exit
[0;32masciinema: recording finished[0m
[0;32masciinema: asciicast saved to /logs/agent.cast[0m
[?2004hroot@76c15cab1a93:/backup# 
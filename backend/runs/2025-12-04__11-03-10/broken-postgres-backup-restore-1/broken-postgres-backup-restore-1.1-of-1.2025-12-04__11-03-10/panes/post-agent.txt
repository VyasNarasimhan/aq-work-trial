root@76c15cab1a93:/backup# ls -la /backup/; tmux wait -S done
total 40
drwxr-xr-x 1 root root  4096 Dec  4 16:59 .
drwxr-xr-x 1 root root  4096 Dec  4 19:03 ..
-rw-r--r-- 1 root root   945 Dec  4 16:54 backup_metadata.log
-rw-r--r-- 1 root root   718 Dec  4 16:54 database.sql
-rw-r--r-- 1 root root   703 Dec  4 16:54 postgresql.conf
-rw-r--r-- 1 root root 15425 Dec  4 16:54 transactions_backup.json
-rw-r--r-- 1 root root  2351 Dec  4 16:54 users_export.csv
root@76c15cab1a93:/backup# service postgresql start; tmux wait -S done
 * Starting PostgreSQL 16 database server                                                                                                                [ OK ]
root@76c15cab1a93:/backup# cat /backup/backup_metadata.log; tmux wait -S done
[2025-09-28 03:00:00] INFO: Starting database backup process
[2025-09-28 03:00:01] INFO: Backup initiated by: admin
[2025-09-28 03:00:01] INFO: Backup type: Full
[2025-09-28 03:00:02] INFO: Connecting to database: production_db
[2025-09-28 03:00:03] INFO: Connection successful
[2025-09-28 03:00:05] INFO: Backing up table: users
[2025-09-28 03:00:06] INFO: Table 'users' backed up successfully - 30 rows
[2025-09-28 03:00:07] INFO: Backing up table: transactions
[2025-09-28 03:00:09] INFO: Table 'transactions' backed up successfully - 100 rows
[2025-09-28 03:00:10] INFO: Total tables backed up: 2
[2025-09-28 03:00:10] INFO: Total rows backed up: 130
[2025-09-28 03:00:11] INFO: Running integrity check
[2025-09-28 03:00:12] INFO: Integrity check: PASSED
[2025-09-28 03:00:13] INFO: Backup completed successfully
[2025-09-28 03:00:13] INFO: Backup file: /backup/database.sql
[2025-09-28 03:00:13] INFO: Backup timestamp: 2025-09-28 03:00:00
root@76c15cab1a93:/backup# head -20 /backup/database.sql; tmux wait -S done
-- PostgreSQL database dump
-- This dump contains the schema and some sample data
-- Note: Some statements may have errors that need to be fixed

-- Create users table
CREATE TABLE IF NOT EXISTS users (
    user_id INTEGER PRIMARY KEY,
    username VARCHAR(100) NOT NULL,
    email VARCHAR(255) NOT NULL,
    created_at TIMESTAMP,
    status VARCHAR(20)
);

-- Create transactions table
CREATE TABLE IF NOT EXISTS transactions (
    transaction_id INTEGER PRIMARY KEY,
    user_id INTEGER,
    amount DECIMAL(10,2),
    timestamp TIMESTAMP,
    description TEXT,
root@76c15cab1a93:/backup# head -20 /backup/users_export.csv; tmux wait -S done
user_id,username,email,created_at,status
1,alice_smith,alice_smith@example.com,2024-11-21 01:25:46,inactive
2,bob_jones,bob_jones@example.com,2025-06-28 01:25:46,active
3,charlie_brown,charlie_brown@example.com,2025-08-13 01:25:46,suspended
4,diana_prince,diana_prince@example.com,2025-08-05 01:25:46,inactive
5,eve_adams,eve_adams@example.com,2025-09-08 01:25:46,inactive
6,frank_white,frank_white@example.com,2025-09-04 01:25:46,active
7,grace_lee,grace_lee@example.com,2025-06-05 01:25:46,active
8,henry_ford,henry_ford@example.com,2025-07-25 01:25:46,inactive
9,iris_west,iris_west@example.com,2025-03-23 01:25:46,suspended
10,jack_ryan,jack_ryan@example.com,2024-10-19 01:25:46,inactive
11,kate_mills,kate_mills@example.com,2025-06-27 01:25:46,active
12,leo_king,leo_king@example.com,2024-12-21 01:25:46,inactive
13,mary_jane,mary_jane@example.com,2025-10-03 01:25:46,suspended
14,nick_fury,nick_fury@example.com,2025-04-03 01:25:46,suspended
15,olivia_pope,olivia_pope@example.com,2025-06-01 01:25:46,active
16,peter_parker,peter_parker@example.com,2025-01-02 01:25:46,inactive
17,quinn_baker,quinn_baker@example.com,2025-01-22 01:25:46,suspended
18,rachel_green,rachel_green@example.com,2025-04-01 01:25:46,inactive
19,steve_rogers,steve_rogers@example.com,2025-06-28 01:25:46,active
root@76c15cab1a93:/backup# head -20 /backup/transactions_backup.json; tmux wait -S done
[
  {
    "transaction_id": 1,
    "user_id": 16,
    "amount": 46.0,
    "timestamp": "2025-07-16 01:25:56",
    "description": "Subscription"
  },
  {
    "transaction_id": 2,
    "user_id": 6,
    "amount": 646.05,
    "timestamp": "2025-05-02 01:25:56",
    "description": "Payment"
  },
  {
    "transaction_id": 3,
    "user_id": 29,
    "amount": 186.76,
    "timestamp": "2025-07-30 01:25:56",
root@76c15cab1a93:/backup# cat > /backup/restore_database.py << 'EOF'
> import psycopg2
> import csv
> import json
_id, username, email, created_at, s> import re
> from decimal import Decimal
>
tatus)
            VALUES (%s, %s, %s, > # Create database and restore schema
> def create_database():
, user['username'], use>     # Connect to default postgres database
>     conn = psycopg2.connect(dbname='postgres', user='postgres', host='localhost')
>     conn.autocommit = True
SERT >     cur = conn.cursor()
>
>     # Drop if exists and create new database
>     cur.execute("DROP DATABASE IF EXISTS production_db")
>     cur.execute("CREATE DATABASE production_db")
>     cur.close()
timesta>     conn.close()
'de>
>     # Connect to new database and create tables
>     conn = psycopg2.connect(dbname='production_db', user='postgres', host='localhost')
>     cur = conn.cursor()
>
>     # Create users table
>     cur.execute("""
production_db', user='postgres', host='localhost')>         CREATE TABLE users (
>             user_id INTEGER PRIMARY KEY,
>             username VARCHAR(255) NOT NULL,
>             email VARCHAR(255) NOT NULL,
>             created_at TIMESTAMP,
*) FR>             status VARCHAR(50)
>         )
>     """)
>
>     # Create transactions table
>     cur.execute("""
>         CREATE TABLE transactions (
>             transaction_id INTEGER PRIMARY KEY,
>             user_id INTEGER,
>             amount DECIMAL(10, 2),
>             timestamp TIMESTAMP,
tus = 'active'")
    active_users = cur.fetchone()[0]

    # Total transactions
    cur.execute("SELECT COUNT(*) FROM transactions")
    total_transactions = cur.fetchone()[0]

    # Total amount
    cur.execute("SELECT COALESCE(SUM(amount), 0) FROM transactions>             description TEXT
>         )
tchon>     """)
>

 >     conn.commit()
>     cur.close()
otal>     conn.close()
   >
> # Clean users data
> def clean_users():
>     valid_statuses = ['active', 'inactive', 'suspended']
>     email_pattern = re.compile(r'^[^@]+@[^@]+$')
>
avg_per_user = 0

    cur.close()
    conn.close()

    # Write stats
    with >     clean_data = []
backup/db_sta>     with open('/backup/users_export.csv', 'r') as f:
>         reader = csv.DictReader(f)
===>         for row in reader:
rit>             # Check for missing user_id
>             if not row.get('user_id') or row['user_id'].strip() == '':
>                 continue
>
>             # Check for empty username
>             if not row.get('username') or row['username'].strip() == '':
>                 continue
>
>             # Check for invalid email
>             email = row.get('email', '').strip()
>             if not email or not email_pattern.match(email):
>                 continue
ute("""
        SELECT u.>
>             # Check for invalid status
>             status = row.get('status', '').strip().lower()
>             if status not in valid_statuses:
>                 continue
>
l_amount DESC>             clean_data.append({
>                 'user_id': row['user_id'].strip(),
>                 'username': row['username'].strip(),
ers>                 'email': email,
>                 'created_at': row.get('created_at', '').strip(),
>                 'status': status
>             })
t'>
>     # Write cleaned data
>     with open('/backup/clean_users.csv', 'w', newline='') as f:
>         writer = csv.DictWriter(f, fieldnames=['user_id', 'username', 'email', 'created_at', 'status'])
>         writer.writeheader()
ackup/backup_metadata.log', '>         writer.writerows(clean_data)
>
>     return clean_data
>
> # Clean transactions data
> def clean_transactions():
>     with open('/backup/transactions_backup.json', 'r') as f:
>         transactions = json.load(f)
imestamp:' in line>
   >     valid_transactions = []
>     for txn in transactions:
>         # Check for null transaction_id
>         if txn.get('transaction_id') is None:
>             continue
>
>         # Check for null or negative amounts
>         amount = txn.get('amount')
>         if amount is None or amount <= 0:
>             continue
 >
>         # Check for missing timestamp
    elif 'Integrity check:' in line:
          >         if not txn.get('timestamp'):
>             continue
>
>         # Check for valid user_id (1-30)
>         user_id = txn.get('user_id')
>         if user_id is None or user_id < 1 or user_id > 30:
>             continue
   f.write(>
up >         valid_transactions.append(txn)
f.write>
>     # Write valid transactions
_backed_>     with open('/backup/valid_transactions.json', 'w') as f:
>         json.dump(valid_transactions, f, indent=2)
>         f.write('\n')
   f.write(f'Integrity Check: {integrity_check}\n')

# Main execution
if >
>     return valid_transactions
>
> # Import data into database
> def import_data(users, transactions):
>     conn = psycopg2.connect(dbname='production_db', user='postgres', host='localhost')
>     cur = conn.cursor()
>
>     # Import users
ons()
  >     for user in users:
>         cur.execute("""
>             INSERT INTO users (user_id, username, email, created_at, status)
>             VALUES (%s, %s, %s, %s, %s)
>         """, (user['user_id'], user['username'], user['email'], user['created_at'], user['status']))
>
>     # Import transactions
>     for txn in transactions:
co>         cur.execute("""
>             INSERT INTO transactions (transaction_id, user_id, amount, timestamp, description)
')>             VALUES (%s, %s, %s, %s, %s)
>         """, (txn['transaction_id'], txn['user_id'], txn['amount'], txn['timestamp'], txn.get('description', '')))
>
>     conn.commit()
>     cur.close()
>     conn.close()
>
> # Generate database statistics
> def generate_stats():
>     conn = psycopg2.connect(dbname='production_db', user='postgres', host='localhost')
>     cur = conn.cursor()
>
>     # Total users
>     cur.execute("SELECT COUNT(*) FROM users")
>     total_users = cur.fetchone()[0]
>
>     # Active users
>     cur.execute("SELECT COUNT(*) FROM users WHERE status = 'active'")
>     active_users = cur.fetchone()[0]
>
>     # Total transactions
>     cur.execute("SELECT COUNT(*) FROM transactions")
>     total_transactions = cur.fetchone()[0]
>
>     # Total amount
>     cur.execute("SELECT COALESCE(SUM(amount), 0) FROM transactions")
>     total_amount = float(cur.fetchone()[0])
>
>     # Average per user
>     if total_users > 0:
>         avg_per_user = total_amount / total_users
>     else:
>         avg_per_user = 0
>
>     cur.close()
>     conn.close()
>
>     # Write stats
>     with open('/backup/db_stats.txt', 'w') as f:
>         f.write('DATABASE STATISTICS\n')
>         f.write('==================\n')
>         f.write(f'Total Users: {total_users}\n')
>         f.write(f'Active Users: {active_users}\n')
>         f.write(f'Total Transactions: {total_transactions}\n')
>         f.write(f'Total Amount: {total_amount:.2f}\n')
>         f.write(f'Average per User: {avg_per_user:.2f}\n')
>
> # Generate top users report
> def generate_top_users():
>     conn = psycopg2.connect(dbname='production_db', user='postgres', host='localhost')
>     cur = conn.cursor()
>
>     cur.execute("""
>         SELECT u.username, COALESCE(SUM(t.amount), 0) as total_amount
>         FROM users u
>         LEFT JOIN transactions t ON u.user_id = t.user_id
>         GROUP BY u.username
>         ORDER BY total_amount DESC, u.username ASC
>         LIMIT 10
>     """)
>
>     results = cur.fetchall()
>     cur.close()
>     conn.close()
>
>     # Write top users
>     with open('/backup/top_users.csv', 'w', newline='') as f:
>         writer = csv.writer(f)
>         writer.writerow(['username', 'total_amount'])
>         for username, total_amount in results:
>             writer.writerow([username, f'{float(total_amount):.2f}'])
>
> # Generate backup verification
> def generate_verification():
>     with open('/backup/backup_metadata.log', 'r') as f:
>         content = f.read()
>
>     backup_date = ''
>     tables_backed_up = ''
>     total_rows = ''
>     integrity_check = ''
>
>     for line in content.split('\n'):
>         if 'Backup timestamp:' in line:
>             backup_date = line.split('Backup timestamp:')[1].strip()
>         elif 'Total tables backed up:' in line:
>             tables_backed_up = line.split('Total tables backed up:')[1].strip()
>         elif 'Total rows backed up:' in line:
>             total_rows = line.split('Total rows backed up:')[1].strip()
>         elif 'Integrity check:' in line:
>             integrity_check = line.split('Integrity check:')[1].strip()
>
>     with open('/backup/backup_verification.txt', 'w') as f:
>         f.write('BACKUP VERIFICATION\n')
>         f.write('===================\n')
>         f.write(f'Backup Date: {backup_date}\n')
>         f.write(f'Tables Backed Up: {tables_backed_up}\n')
>         f.write(f'Total Rows: {total_rows}\n')
>         f.write(f'Integrity Check: {integrity_check}\n')
>
> # Main execution
> if __name__ == '__main__':
>     print('Creating database...')
>     create_database()
>
>     print('Cleaning users data...')
>     users = clean_users()
>
>     print('Cleaning transactions data...')
>     transactions = clean_transactions()
>
>     print('Importing data...')
>     import_data(users, transactions)
>
>     print('Generating statistics...')
>     generate_stats()
>
>     print('Generating top users report...')
>     generate_top_users()
>
>     print('Generating backup verification...')
>     generate_verification()
>
>     print('Creating recovery completion marker...')
>     with open('/backup/recovery_complete.txt', 'w') as f:
>         f.write('RECOVERY_SUCCESSFUL\n')
>
>     print('Recovery complete!')
> EOF
root@76c15cab1a93:/backup# python3 /backup/restore_database.py; tmux wait -S done
Traceback (most recent call last):
  File "/backup/restore_database.py", line 1, in <module>
    import psycopg2
ModuleNotFoundError: No module named 'psycopg2'
root@76c15cab1a93:/backup# pip3 install psycopg2-binary; tmux wait -S done
bash: pip3: command not found
root@76c15cab1a93:/backup# python3 /backup/restore_database.py; tmux wait -S done
Traceback (most recent call last):
  File "/backup/restore_database.py", line 1, in <module>
    import psycopg2
ModuleNotFoundError: No module named 'psycopg2'
root@76c15cab1a93:/backup# cat > /backup/restore_database.py << 'EOF'
> import subprocess
> import csv
> import json
> import re
', cmd],
 > import os
>
> # Create database and restore schema
> def create_database():
>     # Drop and create database
>     subprocess.run(['psql', '-U', 'postgres', '-c', 'DROP DATABASE IF EXISTS production_db'],
>                    env={**os.environ, 'PGHOST': 'localhost'})
ount,>     subprocess.run(['psql', '-U', 'postgres', '-c', 'CREATE DATABASE production_db'],
moun>                    env={**os.environ, 'PGHOST': 'localhost'})
>
['psq>     # Create users table
>     subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-c', '''
>         CREATE TABLE users (
>             user_id INTEGER PRIMARY KEY,
 database statistics
def generate_stats()>             username VARCHAR(255) NOT NULL,
PGHOST': 'localh>             email VARCHAR(255) NOT NULL,
>             created_at TIMESTAMP,
>             status VARCHAR(50)
>         )
 '-t', '-c>     '''], env={**os.environ, 'PGHOST': 'localhost'})
>
     >     # Create transactions table
>     subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-c', '''
>         CREATE TABLE transactions (
>             transaction_id INTEGER PRIMARY KEY,
>             user_id INTEGER,
>             amount DECIMAL(10, 2),
>             timestamp TIMESTAMP,
>             description TEXT
>         )
  a>     '''], env={**os.environ, 'PGHOST': 'localhost'})
>
> # Clean users data
> def clean_users():
>     valid_statuses = ['active', 'inactive', 'suspended']
production_db', >     email_pattern = re.compile(r'^[^@]+@[^@]+$')
>
>     clean_data = []
>     with open('/backup/users_export.csv', 'r') as f:
>         reader = csv.DictReader(f)
>         for row in reader:
m>             # Check for missing user_id
>             if not row.get('user_id') or row['user_id'].strip() == '':
>                 continue
ra>
>             # Check for empty username
>             if not row.get('username') or row['username'].strip() == '':
>                 continue
>
f>             # Check for invalid email
>             email = row.get('email', '').strip()
>             if not email or not email_pattern.match(email):
>                 continue
 >
f:
        f.>             # Check for invalid status
>             status = row.get('status', '').strip().lower()
>             if status not in valid_statuses:
>                 continue
>
>             clean_data.append({
>                 'user_id': row['user_id'].strip(),
>                 'username': row['username'].strip(),
>                 'email': email,
>                 'created_at': row.get('created_at', '').strip(),
>                 'status': status
hos>             })
>
>     # Write cleaned data
>     with open('/backup/clean_users.csv', 'w', newline='') as f:
>         writer = csv.DictWriter(f, fieldnames=['user_id', 'username', 'email', 'created_at', 'status'])
>         writer.writeheader()
>         writer.writerows(clean_data)
>

    >     return clean_data
>
> # Clean transactions data
> def clean_transactions():
>     with open('/backup/transactions_backup.json', 'r') as f:
 lines = resu>         transactions = json.load(f)
>
 >     valid_transactions = []
>     for txn in transactions:
>         # Check for null transaction_id
'') as f:
        writer = cs>         if txn.get('transaction_id') is None:
>             continue
>
, 'total_amount'])
        fo>         # Check for null or negative amounts
>         amount = txn.get('amount')
>         if amount is None or amount <= 0:
>             continue
2:
>
>         # Check for missing timestamp
>         if not txn.get('timestamp'):
])>             continue
>
>         # Check for valid user_id (1-30)
>         user_id = txn.get('user_id')
>         if user_id is None or user_id < 1 or user_id > 30:
>             continue
   >
>         valid_transactions.append(txn)
>
    t>     # Write valid transactions
  total_>     with open('/backup/valid_transactions.json', 'w') as f:
 in cont>         json.dump(valid_transactions, f, indent=2)
n >         f.write('\n')
>
>     return valid_transactions
>
> # Import data into database
> def import_data(users, transactions):
>     # Import users
>     for user in users:
lit('>         cmd = f"INSERT INTO users (user_id, username, email, created_at, status) VALUES ({user['user_id']}, '{user['username']}', '{user['email']}', '{us
er['created_at']}', '{user['status']}')"
>         subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-c', cmd],
>                       env={**os.environ, 'PGHOST': 'localhost'})
>
(>     # Import transactions
)
 >     for txn in transactions:
>         desc = txn.get('description', '').replace("'", "''")
>         cmd = f"INSERT INTO transactions (transaction_id, user_id, amount, timestamp, description) VALUES ({txn['transaction_id']}, {txn['user_id']}, {txn['am
ount']}, '{txn['timestamp']}', '{desc}')"
>         subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-c', cmd],
ani>                       env={**os.environ, 'PGHOST': 'localhost'})
>
n> # Generate database statistics

    > def generate_stats():
>     env = {**os.environ, 'PGHOST': 'localhost'}
'>
)
   >     # Total users
rs>     result = subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-t', '-c', 'SELECT COUNT(*) FROM users'],
>                            capture_output=True, text=True, env=env)
>     total_users = int(result.stdout.strip())
ication()
>

>     # Active users
g>     result = subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-t', '-c', "SELECT COUNT(*) FROM users WHERE status = 'active'"],
>                            capture_output=True, text=True, env=env)
>     active_users = int(result.stdout.strip())
>
>     # Total transactions
>     result = subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-t', '-c', 'SELECT COUNT(*) FROM transactions'],
>                            capture_output=True, text=True, env=env)
>     total_transactions = int(result.stdout.strip())
>
>     # Total amount
>     result = subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-t', '-c', 'SELECT COALESCE(SUM(amount), 0) FROM transactions'],
>                            capture_output=True, text=True, env=env)
>     total_amount = float(result.stdout.strip())
>
>     # Average per user
>     if total_users > 0:
>         avg_per_user = total_amount / total_users
>     else:
>         avg_per_user = 0
>
>     # Write stats
>     with open('/backup/db_stats.txt', 'w') as f:
>         f.write('DATABASE STATISTICS\n')
>         f.write('==================\n')
>         f.write(f'Total Users: {total_users}\n')
>         f.write(f'Active Users: {active_users}\n')
>         f.write(f'Total Transactions: {total_transactions}\n')
>         f.write(f'Total Amount: {total_amount:.2f}\n')
>         f.write(f'Average per User: {avg_per_user:.2f}\n')
>
> # Generate top users report
> def generate_top_users():
>     env = {**os.environ, 'PGHOST': 'localhost'}
>
>     result = subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-t', '-c', '''
>         SELECT u.username, COALESCE(SUM(t.amount), 0) as total_amount
>         FROM users u
>         LEFT JOIN transactions t ON u.user_id = t.user_id
>         GROUP BY u.username
>         ORDER BY total_amount DESC, u.username ASC
>         LIMIT 10
>     '''], capture_output=True, text=True, env=env)
>
>     lines = result.stdout.strip().split('\n')
>
>     # Write top users
>     with open('/backup/top_users.csv', 'w', newline='') as f:
>         writer = csv.writer(f)
>         writer.writerow(['username', 'total_amount'])
>         for line in lines:
>             if line.strip():
>                 parts = [p.strip() for p in line.split('|')]
>                 if len(parts) == 2:
>                     username = parts[0]
>                     amount = float(parts[1])
>                     writer.writerow([username, f'{amount:.2f}'])
>
> # Generate backup verification
> def generate_verification():
>     with open('/backup/backup_metadata.log', 'r') as f:
>         content = f.read()
>
>     backup_date = ''
>     tables_backed_up = ''
>     total_rows = ''
>     integrity_check = ''
>
>     for line in content.split('\n'):
>         if 'Backup timestamp:' in line:
>             backup_date = line.split('Backup timestamp:')[1].strip()
>         elif 'Total tables backed up:' in line:
>             tables_backed_up = line.split('Total tables backed up:')[1].strip()
>         elif 'Total rows backed up:' in line:
>             total_rows = line.split('Total rows backed up:')[1].strip()
>         elif 'Integrity check:' in line:
>             integrity_check = line.split('Integrity check:')[1].strip()
>
>     with open('/backup/backup_verification.txt', 'w') as f:
>         f.write('BACKUP VERIFICATION\n')
>         f.write('===================\n')
>         f.write(f'Backup Date: {backup_date}\n')
>         f.write(f'Tables Backed Up: {tables_backed_up}\n')
>         f.write(f'Total Rows: {total_rows}\n')
>         f.write(f'Integrity Check: {integrity_check}\n')
>
> # Main execution
> if __name__ == '__main__':
>     print('Creating database...')
>     create_database()
>
>     print('Cleaning users data...')
>     users = clean_users()
>
>     print('Cleaning transactions data...')
>     transactions = clean_transactions()
>
>     print('Importing data...')
>     import_data(users, transactions)
>
>     print('Generating statistics...')
>     generate_stats()
>
>     print('Generating top users report...')
>     generate_top_users()
>
>     print('Generating backup verification...')
>     generate_verification()
>
>     print('Creating recovery completion marker...')
>     with open('/backup/recovery_complete.txt', 'w') as f:
>         f.write('RECOVERY_SUCCESSFUL\n')
>
>     print('Recovery complete!')
> EOF
root@76c15cab1a93:/backup# python3 /backup/restore_database.py; tmux wait -S done
Creating database...
Password for user postgres: Traceback (most recent call last):
  File "/backup/restore_database.py", line 227, in <module>
    create_database()
  File "/backup/restore_database.py", line 10, in create_database
    subprocess.run(['psql', '-U', 'postgres', '-c', 'DROP DATABASE IF EXISTS production_db'],
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/subprocess.py", line 550, in run
    stdout, stderr = process.communicate(input, timeout=timeout)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/subprocess.py", line 1201, in communicate
    self.wait()
  File "/usr/lib/python3.12/subprocess.py", line 1264, in wait
    return self._wait(timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/subprocess.py", line 2053, in _wait
    (pid, sts) = self._try_wait(0)
                 ^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/subprocess.py", line 2011, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

root@76c15cab1a93:/backup# sed -i 's/peer/trust/g' /etc/postgresql/*/main/pg_hba.conf; tmux wait -S done
root@76c15cab1a93:/backup# sed -i 's/md5/trust/g' /etc/postgresql/*/main/pg_hba.conf; tmux wait -S done
root@76c15cab1a93:/backup# service postgresql restart; tmux wait -S done
 * Restarting PostgreSQL 16 database server                                                                                                              [ OK ]
root@76c15cab1a93:/backup# python3 /backup/restore_database.py; tmux wait -S done
Creating database...
Password for user postgres: Traceback (most recent call last):
  File "/backup/restore_database.py", line 227, in <module>
    create_database()
  File "/backup/restore_database.py", line 10, in create_database
    subprocess.run(['psql', '-U', 'postgres', '-c', 'DROP DATABASE IF EXISTS production_db'],
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/subprocess.py", line 550, in run
    stdout, stderr = process.communicate(input, timeout=timeout)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/subprocess.py", line 1201, in communicate
    self.wait()
  File "/usr/lib/python3.12/subprocess.py", line 1264, in wait
    return self._wait(timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/subprocess.py", line 2053, in _wait
    (pid, sts) = self._try_wait(0)
                 ^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/subprocess.py", line 2011, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

root@76c15cab1a93:/backup# cat /etc/postgresql/*/main/pg_hba.conf | grep -v '^#' | grep -v '^$'; tmux wait -S done
local   all             postgres                                trust
local   all             all                                     trust
host    all             all             127.0.0.1/32            scram-sha-256
host    all             all             ::1/128                 scram-sha-256
local   replication     all                                     trust
host    replication     all             127.0.0.1/32            scram-sha-256
host    replication     all             ::1/128                 scram-sha-256
root@76c15cab1a93:/backup# sed -i 's/scram-sha-256/trust/g' /etc/postgresql/*/main/pg_hba.conf; tmux wait -S done
root@76c15cab1a93:/backup# service postgresql restart; tmux wait -S done
 * Restarting PostgreSQL 16 database server                                                                                                              [ OK ]
root@76c15cab1a93:/backup# python3 /backup/restore_database.py; tmux wait -S done
Creating database...
NOTICE:  database "production_db" does not exist, skipping
DROP DATABASE
CREATE DATABASE
CREATE TABLE
CREATE TABLE
Cleaning users data...
Cleaning transactions data...
Traceback (most recent call last):
  File "/backup/restore_database.py", line 233, in <module>
    transactions = clean_transactions()
                   ^^^^^^^^^^^^^^^^^^^^
  File "/backup/restore_database.py", line 93, in clean_transactions
    if amount is None or amount <= 0:
                         ^^^^^^^^^^^
TypeError: '<=' not supported between instances of 'str' and 'int'
root@76c15cab1a93:/backup# cat > /backup/restore_database.py << 'EOF'
> import subprocess
> import csv
\n')

    return valid_tr> import json
> import re
> import os
>
> # Create database and restore schema
> def create_database():
>     # Drop and create database
>     subprocess.run(['psql', '-U', 'postgres', '-c', 'DROP DATABASE IF EXISTS production_db'],
>                    env={**os.environ, 'PGHOST': 'localhost'})
>     subprocess.run(['psql', '-U', 'postgres', '-c', 'CREATE DATABASE production_db'],
>                    env={**os.environ, 'PGHOST': 'localhost'})
>
>     # Create users table
>     subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-c', '''
>         CREATE TABLE users (
t(>             user_id INTEGER PRIMARY KEY,
>             username VARCHAR(255) NOT NULL,
>             email VARCHAR(255) NOT NULL,
>             created_at TIMESTAMP,
>             status VARCHAR(50)
, {txn['user_id']}, {tx>         )
unt'>     '''], env={**os.environ, 'PGHOST': 'localhost'})
>
>     # Create transactions table
>     subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-c', '''
OS>         CREATE TABLE transactions (
u>             transaction_id INTEGER PRIMARY KEY,
>             user_id INTEGER,
>             amount DECIMAL(10, 2),
>             timestamp TIMESTAMP,
>             description TEXT
>         )
>     '''], env={**os.environ, 'PGHOST': 'localhost'})
>
> # Clean users data
> def clean_users():
>     valid_statuses = ['active', 'inactive', 'suspended']
>     email_pattern = re.compile(r'^[^@]+@[^@]+$')
>
>     clean_data = []
>     with open('/backup/users_export.csv', 'r') as f:
>         reader = csv.DictReader(f)
>         for row in reader:
>             # Check for missing user_id
>             if not row.get('user_id') or row['user_id'].strip() == '':
>                 continue
>
>             # Check for empty username
>             if not row.get('username') or row['username'].strip() == '':
 F>                 continue
>
>             # Check for invalid email
>             email = row.get('email', '').strip()
>             if not email or not email_pattern.match(email):

    result = subproce>                 continue
>
>             # Check for invalid status
>             status = row.get('status', '').strip().lower()
amount), 0) FROM transactions'],
             >             if status not in valid_statuses:
>                 continue
>
>             clean_data.append({
>                 'user_id': row['user_id'].strip(),
>                 'username': row['username'].strip(),
>                 'email': email,
# >                 'created_at': row.get('created_at', '').strip(),
>                 'status': status
>             })
>
>     # Write cleaned data
>     with open('/backup/clean_users.csv', 'w', newline='') as f:
        f.write(>         writer = csv.DictWriter(f, fieldnames=['user_id', 'username', 'email', 'created_at', 'status'])
>         writer.writeheader()
>         writer.writerows(clean_data)
write(f>
>     return clean_data
er>
> # Clean transactions data
> def clean_transactions():
>     with open('/backup/transactions_backup.json', 'r') as f:
>         transactions = json.load(f)
>
>     valid_transactions = []
>     for txn in transactions:
c',>         # Check for null transaction_id
>         if txn.get('transaction_id') is None:
>             continue
>
>         # Check for null or negative amounts
    >         amount = txn.get('amount')
R >         if amount is None:
>             continue
M>
>         # Convert to float if it's a string
>         try:
    >             amount_val = float(amount)
>         except (ValueError, TypeError):
>             continue
_user>
s.csv', '>         if amount_val <= 0:
>             continue
w', newline='') as f:
        writer = csv.writer>
>         # Check for missing timestamp
>         if not txn.get('timestamp'):
>             continue
>
>         # Check for valid user_id (1-30)
>         user_id = txn.get('user_id')
 i>         if user_id is None:
>             continue
>
ts[0]>         try:
>             user_id_val = int(user_id)
>         except (ValueError, TypeError):
>             continue
>
 Generate>         if user_id_val < 1 or user_id_val > 30:
e_verification()>             continue
:
    with open('/bac>
>         valid_transactions.append(txn)
      con>
tent >     # Write valid transactions
>     with open('/backup/valid_transactions.json', 'w') as f:
>         json.dump(valid_transactions, f, indent=2)
>         f.write('\n')
>
>     return valid_transactions
>
tamp:' in line:
          > # Import data into database
> def import_data(users, transactions):
>     # Import users
ables>     for user in users:
>         cmd = f"INSERT INTO users (user_id, username, email, created_at, status) VALUES ({user['user_id']}, '{user['username']}', '{user['email']}', '{user['c
reated_at']}', '{user['status']}')"
>         subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-c', cmd],
>                       env={**os.environ, 'PGHOST': 'localhost'}, capture_output=True)
with open('/backup/backup_verification.txt', '>
w') a>     # Import transactions
s f:
        f.write('BACK>     for txn in transactions:
>         desc = txn.get('description', '').replace("'", "''")
Date>         cmd = f"INSERT INTO transactions (transaction_id, user_id, amount, timestamp, description) VALUES ({txn['transaction_id']}, {txn['user_id']}, {txn
['amount']}, '{txn['timestamp']}', '{desc}')"
>         subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-c', cmd],
>                       env={**os.environ, 'PGHOST': 'localhost'}, capture_output=True)
>
n> # Generate database statistics
   > def generate_stats():
ean_t>     env = {**os.environ, 'PGHOST': 'localhost'}
orting data...'>
>     # Total users
users>     result = subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-t', '-c', 'SELECT COUNT(*) FROM users'],
>                            capture_output=True, text=True, env=env)
>     total_users = int(result.stdout.strip())
>
>     # Active users
>     result = subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-t', '-c', "SELECT COUNT(*) FROM users WHERE status = 'active'"],
>                            capture_output=True, text=True, env=env)
)
EOF
>     active_users = int(result.stdout.strip())
>
>     # Total transactions
>     result = subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-t', '-c', 'SELECT COUNT(*) FROM transactions'],
>                            capture_output=True, text=True, env=env)
>     total_transactions = int(result.stdout.strip())
>
>     # Total amount
>     result = subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-t', '-c', 'SELECT COALESCE(SUM(amount), 0) FROM transactions'],
>                            capture_output=True, text=True, env=env)
>     total_amount = float(result.stdout.strip())
>
>     # Average per user
>     if total_users > 0:
>         avg_per_user = total_amount / total_users
>     else:
>         avg_per_user = 0
>
>     # Write stats
>     with open('/backup/db_stats.txt', 'w') as f:
>         f.write('DATABASE STATISTICS\n')
>         f.write('==================\n')
>         f.write(f'Total Users: {total_users}\n')
>         f.write(f'Active Users: {active_users}\n')
>         f.write(f'Total Transactions: {total_transactions}\n')
>         f.write(f'Total Amount: {total_amount:.2f}\n')
>         f.write(f'Average per User: {avg_per_user:.2f}\n')
>
> # Generate top users report
> def generate_top_users():
>     env = {**os.environ, 'PGHOST': 'localhost'}
>
>     result = subprocess.run(['psql', '-U', 'postgres', '-d', 'production_db', '-t', '-c', '''
>         SELECT u.username, COALESCE(SUM(t.amount), 0) as total_amount
>         FROM users u
>         LEFT JOIN transactions t ON u.user_id = t.user_id
>         GROUP BY u.username
>         ORDER BY total_amount DESC, u.username ASC
>         LIMIT 10
>     '''], capture_output=True, text=True, env=env)
>
>     lines = result.stdout.strip().split('\n')
>
>     # Write top users
>     with open('/backup/top_users.csv', 'w', newline='') as f:
>         writer = csv.writer(f)
>         writer.writerow(['username', 'total_amount'])
>         for line in lines:
>             if line.strip():
>                 parts = [p.strip() for p in line.split('|')]
>                 if len(parts) == 2:
>                     username = parts[0]
>                     amount = float(parts[1])
>                     writer.writerow([username, f'{amount:.2f}'])
>
> # Generate backup verification
> def generate_verification():
>     with open('/backup/backup_metadata.log', 'r') as f:
>         content = f.read()
>
>     backup_date = ''
>     tables_backed_up = ''
>     total_rows = ''
>     integrity_check = ''
>
>     for line in content.split('\n'):
>         if 'Backup timestamp:' in line:
>             backup_date = line.split('Backup timestamp:')[1].strip()
>         elif 'Total tables backed up:' in line:
>             tables_backed_up = line.split('Total tables backed up:')[1].strip()
>         elif 'Total rows backed up:' in line:
>             total_rows = line.split('Total rows backed up:')[1].strip()
>         elif 'Integrity check:' in line:
>             integrity_check = line.split('Integrity check:')[1].strip()
>
>     with open('/backup/backup_verification.txt', 'w') as f:
>         f.write('BACKUP VERIFICATION\n')
>         f.write('===================\n')
>         f.write(f'Backup Date: {backup_date}\n')
>         f.write(f'Tables Backed Up: {tables_backed_up}\n')
>         f.write(f'Total Rows: {total_rows}\n')
>         f.write(f'Integrity Check: {integrity_check}\n')
>
> # Main execution
> if __name__ == '__main__':
>     print('Creating database...')
>     create_database()
>
>     print('Cleaning users data...')
>     users = clean_users()
>
>     print('Cleaning transactions data...')
>     transactions = clean_transactions()
>
>     print('Importing data...')
>     import_data(users, transactions)
>
>     print('Generating statistics...')
>     generate_stats()
>
>     print('Generating top users report...')
>     generate_top_users()
>
>     print('Generating backup verification...')
>     generate_verification()
>
>     print('Creating recovery completion marker...')
>     with open('/backup/recovery_complete.txt', 'w') as f:
>         f.write('RECOVERY_SUCCESSFUL\n')
>
>     print('Recovery complete!')
> EOF
root@76c15cab1a93:/backup# python3 /backup/restore_database.py; tmux wait -S done
Creating database...
DROP DATABASE
CREATE DATABASE
CREATE TABLE
CREATE TABLE
Cleaning users data...
Cleaning transactions data...
Importing data...
Generating statistics...
Generating top users report...
Generating backup verification...
Creating recovery completion marker...
Recovery complete!
root@76c15cab1a93:/backup# ls -la /backup/*.csv /backup/*.json /backup/*.txt 2>/dev/null; tmux wait -S done
-rw-r--r-- 1 root root   133 Dec  4 19:08 /backup/backup_verification.txt
-rw-r--r-- 1 root root  2052 Dec  4 19:08 /backup/clean_users.csv
-rw-r--r-- 1 root root   145 Dec  4 19:08 /backup/db_stats.txt
-rw-r--r-- 1 root root    20 Dec  4 19:08 /backup/recovery_complete.txt
-rw-r--r-- 1 root root   230 Dec  4 19:08 /backup/top_users.csv
-rw-r--r-- 1 root root 15425 Dec  4 16:54 /backup/transactions_backup.json
-rw-r--r-- 1 root root  2351 Dec  4 16:54 /backup/users_export.csv
-rw-r--r-- 1 root root 14573 Dec  4 19:08 /backup/valid_transactions.json
root@76c15cab1a93:/backup# echo '=== clean_users.csv ==='; tmux wait -S done
=== clean_users.csv ===
root@76c15cab1a93:/backup# head -5 /backup/clean_users.csv; tmux wait -S done
user_id,username,email,created_at,status
1,alice_smith,alice_smith@example.com,2024-11-21 01:25:46,inactive
2,bob_jones,bob_jones@example.com,2025-06-28 01:25:46,active
3,charlie_brown,charlie_brown@example.com,2025-08-13 01:25:46,suspended
4,diana_prince,diana_prince@example.com,2025-08-05 01:25:46,inactive
root@76c15cab1a93:/backup# echo '=== valid_transactions.json ==='; tmux wait -S done
=== valid_transactions.json ===
root@76c15cab1a93:/backup# head -20 /backup/valid_transactions.json; tmux wait -S done
[
  {
    "transaction_id": 1,
    "user_id": 16,
    "amount": 46.0,
    "timestamp": "2025-07-16 01:25:56",
    "description": "Subscription"
  },
  {
    "transaction_id": 2,
    "user_id": 6,
    "amount": 646.05,
    "timestamp": "2025-05-02 01:25:56",
    "description": "Payment"
  },
  {
    "transaction_id": 3,
    "user_id": 29,
    "amount": 186.76,
    "timestamp": "2025-07-30 01:25:56",
root@76c15cab1a93:/backup# echo '=== db_stats.txt ==='; tmux wait -S done
=== db_stats.txt ===
root@76c15cab1a93:/backup# cat /backup/db_stats.txt; tmux wait -S done
DATABASE STATISTICS
==================
Total Users: 30
Active Users: 13
Total Transactions: 100
Total Amount: 53109.46
Average per User: 1770.32
root@76c15cab1a93:/backup# echo '=== top_users.csv ==='; tmux wait -S done
=== top_users.csv ===
root@76c15cab1a93:/backup# cat /backup/top_users.csv; tmux wait -S done
username,total_amount
zara_ahmed,4400.17
alice_smith,3682.87
victor_von,3451.21
donna_noble,3225.49
xavier_prof,2990.51
nick_fury,2709.20
wade_wilson,2678.95
tony_stark,2637.00
frank_white,2539.97
charlie_brown,2525.32
root@76c15cab1a93:/backup# echo '=== backup_verification.txt ==='; tmux wait -S done
=== backup_verification.txt ===
root@76c15cab1a93:/backup# cat /backup/backup_verification.txt; tmux wait -S done
BACKUP VERIFICATION
===================
Backup Date: 2025-09-28 03:00:00
Tables Backed Up: 2
Total Rows: 130
Integrity Check: PASSED
root@76c15cab1a93:/backup# echo '=== recovery_complete.txt ==='; tmux wait -S done
=== recovery_complete.txt ===
root@76c15cab1a93:/backup# cat /backup/recovery_complete.txt; tmux wait -S done
RECOVERY_SUCCESSFUL
root@76c15cab1a93:/backup# psql -U postgres -d production_db -c '\dt'; tmux wait -S done
            List of relations
 Schema |     Name     | Type  |  Owner
--------+--------------+-------+----------
 public | transactions | table | postgres
 public | users        | table | postgres
(2 rows)

root@76c15cab1a93:/backup# psql -U postgres -d production_db -c 'SELECT COUNT(*) FROM users;'; tmux wait -S done
 count
-------
    30
(1 row)

root@76c15cab1a93:/backup# psql -U postgres -d production_db -c 'SELECT COUNT(*) FROM transactions;'; tmux wait -S done
 count
-------
   100
(1 row)

root@76c15cab1a93:/backup# wc -l /backup/clean_users.csv; tmux wait -S done
31 /backup/clean_users.csv
root@76c15cab1a93:/backup# head -3 /backup/clean_users.csv; tmux wait -S done
user_id,username,email,created_at,status
1,alice_smith,alice_smith@example.com,2024-11-21 01:25:46,inactive
2,bob_jones,bob_jones@example.com,2025-06-28 01:25:46,active
root@76c15cab1a93:/backup# tail -1 /backup/clean_users.csv | od -c | head -2; tmux wait -S done
0000000   3   0   ,   d   o   n   n   a   _   n   o   b   l   e   ,   d
0000020   o   n   n   a   _   n   o   b   l   e   @   e   x   a   m   p
root@76c15cab1a93:/backup# wc -l /backup/valid_transactions.json; tmux wait -S done
702 /backup/valid_transactions.json
root@76c15cab1a93:/backup# tail -3 /backup/valid_transactions.json; tmux wait -S done
    "description": "Subscription"
  }
]
root@76c15cab1a93:/backup# for file in /backup/clean_users.csv /backup/valid_transactions.json /backup/db_stats.txt /backup/top_users.csv /backup/backup_verific
ation.txt /backup/recovery_complete.txt; do echo "=== $file ==="  && tail -c 1 "$file" | od -An -tx1; done; tmux wait -S done
=== /backup/clean_users.csv ===
 0a
=== /backup/valid_transactions.json ===
 0a
=== /backup/db_stats.txt ===
 0a
=== /backup/top_users.csv ===
 0a
=== /backup/backup_verification.txt ===
 0a
=== /backup/recovery_complete.txt ===
 0a
root@76c15cab1a93:/backup# echo 'All files verified!'; tmux wait -S done
All files verified!
root@76c15cab1a93:/backup# wc -l /backup/top_users.csv; tmux wait -S done
11 /backup/top_users.csv
root@76c15cab1a93:/backup# cat /backup/top_users.csv; tmux wait -S done
username,total_amount
zara_ahmed,4400.17
alice_smith,3682.87
victor_von,3451.21
donna_noble,3225.49
xavier_prof,2990.51
nick_fury,2709.20
wade_wilson,2678.95
tony_stark,2637.00
frank_white,2539.97
charlie_brown,2525.32
root@76c15cab1a93:/backup# echo '=== Verifying database can be queried ==='; tmux wait -S done
=== Verifying database can be queried ===
root@76c15cab1a93:/backup# psql -U postgres -d production_db -c "SELECT username, email, status FROM users LIMIT 3;"; tmux wait -S done
   username    |           email           |  status
---------------+---------------------------+-----------
 alice_smith   | alice_smith@example.com   | inactive
 bob_jones     | bob_jones@example.com     | active
 charlie_brown | charlie_brown@example.com | suspended
(3 rows)

root@76c15cab1a93:/backup# psql -U postgres -d production_db -c "SELECT transaction_id, user_id, amount FROM transactions LIMIT 3;"; tmux wait -S done
 transaction_id | user_id | amount
----------------+---------+--------
              1 |      16 |  46.00
              2 |       6 | 646.05
              3 |      29 | 186.76
(3 rows)

root@76c15cab1a93:/backup# echo '=== All tasks completed successfully! ==='; tmux wait -S done
=== All tasks completed successfully! ===
root@76c15cab1a93:/backup#

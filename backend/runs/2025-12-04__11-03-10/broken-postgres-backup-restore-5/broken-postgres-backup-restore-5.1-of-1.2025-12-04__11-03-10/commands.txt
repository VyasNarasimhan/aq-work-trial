['asciinema rec --stdin /logs/agent.cast', 'Enter']
['clear', 'Enter']
'ls -la /backup/\n'
'cat backup_metadata.log\n'
'head -20 database.sql\n'
'head -20 users_export.csv\n'
'head -20 transactions_backup.json\n'
'service postgresql start\n'
'cat database.sql\n'
"psql -U postgres -c 'CREATE DATABASE production_db;'\n"
'psql -U postgres -d production_db -f database.sql\n'
"psql -U postgres -d production_db -c '\\dt'\n"
'wc -l users_export.csv\n'
'cat users_export.csv\n'
'cat transactions_backup.json\n'
'python3 << \'EOF\'\nimport csv\nimport json\nimport re\n\n# Clean users CSV\nvalid_users = []\nwith open(\'/backup/users_export.csv\', \'r\') as f:\n    reader = csv.DictReader(f)\n    for row in reader:\n        # Check for missing user_id\n        if not row.get(\'user_id\') or row[\'user_id\'].strip() == \'\':\n            continue\n        # Check for empty username\n        if not row.get(\'username\') or row[\'username\'].strip() == \'\':\n            continue\n        # Check for invalid email (must contain @)\n        if not row.get(\'email\') or \'@\' not in row[\'email\']:\n            continue\n        # Check for valid status\n        if row.get(\'status\') not in [\'active\', \'inactive\', \'suspended\']:\n            continue\n        valid_users.append(row)\n\n# Write cleaned users\nwith open(\'/backup/clean_users.csv\', \'w\', newline=\'\') as f:\n    writer = csv.DictWriter(f, fieldnames=[\'user_id\', \'username\', \'email\', \'created_at\', \'status\'])\n    writer.writeheader()\n    writer.writerows(valid_users)\n\nprint(f"Cleaned users: {len(valid_users)} valid rows")\n\n# Clean transactions JSON\nwith open(\'/backup/transactions_backup.json\', \'r\') as f:\n    transactions = json.load(f)\n\nvalid_transactions = []\nfor txn in transactions:\n    # Check for null or missing transaction_id\n    if txn.get(\'transaction_id\') is None:\n        continue\n    # Check for null or missing user_id, or invalid range\n    if txn.get(\'user_id\') is None or txn[\'user_id\'] < 1 or txn[\'user_id\'] > 30:\n        continue\n    # Check for null, negative, or zero amount\n    try:\n        amount = float(txn.get(\'amount\', 0))\n        if amount <= 0:\n            continue\n    except (ValueError, TypeError):\n        continue\n    # Check for missing timestamp\n    if txn.get(\'timestamp\') is None or txn.get(\'timestamp\') == \'\':\n        continue\n    valid_transactions.append(txn)\n\n# Write valid transactions\nwith open(\'/backup/valid_transactions.json\', \'w\') as f:\n    json.dump(valid_transactions, f, indent=2)\n    f.write(\'\\n\')\n\nprint(f"Valid transactions: {len(valid_transactions)} valid rows")\nEOF\n'
'psql -U postgres -d production_db -c "COPY users(user_id, username, email, created_at, status) FROM \'/backup/clean_users.csv\' WITH (FORMAT csv, HEADER true);"\n'
'python3 << \'EOF\'\nimport json\nimport psycopg2\n\n# Connect to database\nconn = psycopg2.connect(\n    dbname=\'production_db\',\n    user=\'postgres\',\n    host=\'localhost\'\n)\ncur = conn.cursor()\n\n# Load valid transactions\nwith open(\'/backup/valid_transactions.json\', \'r\') as f:\n    transactions = json.load(f)\n\n# Insert transactions\nfor txn in transactions:\n    cur.execute(\n        "INSERT INTO transactions (transaction_id, user_id, amount, timestamp, description) VALUES (%s, %s, %s, %s, %s)",\n        (txn[\'transaction_id\'], txn[\'user_id\'], txn[\'amount\'], txn[\'timestamp\'], txn[\'description\'])\n    )\n\nconn.commit()\nprint(f"Imported {len(transactions)} transactions")\n\ncur.close()\nconn.close()\nEOF\n'
'su - postgres -c "psql -d production_db -c \\"COPY users(user_id, username, email, created_at, status) FROM \'/backup/clean_users.csv\' WITH (FORMAT csv, HEADER true);\\""\n'
'python3 << \'EOF\'\nimport json\n\n# Load valid transactions and create SQL insert statements\nwith open(\'/backup/valid_transactions.json\', \'r\') as f:\n    transactions = json.load(f)\n\nwith open(\'/backup/import_transactions.sql\', \'w\') as f:\n    for txn in transactions:\n        desc = txn[\'description\'].replace("\'", "\'\'")\n        f.write(f"INSERT INTO transactions (transaction_id, user_id, amount, timestamp, description) VALUES ({txn[\'transaction_id\']}, {txn[\'user_id\']}, {txn[\'amount\']}, \'{txn[\'timestamp\']}\', \'{desc}\');\\n")\n\nprint(f"Created SQL file with {len(transactions)} insert statements")\nEOF\n'
'su - postgres -c "psql -d production_db -f /backup/import_transactions.sql"\n'
'su - postgres -c "psql -c \'CREATE DATABASE production_db;\'"\n'
'su - postgres -c "psql -d production_db -f /backup/database.sql"\n'
'su - postgres -c "psql -d production_db -c \'\\\\dt\'"\n'
'su - postgres -c "psql -d production_db -c \\"COPY users(user_id, username, email, created_at, status) FROM \'/backup/clean_users.csv\' WITH (FORMAT csv, HEADER true);\\""\n'
'su - postgres -c "psql -d production_db -f /backup/import_transactions.sql" 2>&1 | head -20\n'
'su - postgres -c "psql -d production_db -c \'SELECT COUNT(*) FROM users;\'"\n'
'su - postgres -c "psql -d production_db -c \'SELECT COUNT(*) FROM transactions;\'"\n'
'python3 << \'EOF\'\nimport subprocess\n\n# Generate database statistics report\nresult = subprocess.run(\n    [\'su\', \'-\', \'postgres\', \'-c\', \n     "psql -d production_db -t -c \\"SELECT COUNT(*) FROM users;\\""],\n    capture_output=True, text=True\n)\ntotal_users = int(result.stdout.strip())\n\nresult = subprocess.run(\n    [\'su\', \'-\', \'postgres\', \'-c\',\n     "psql -d production_db -t -c \\"SELECT COUNT(*) FROM users WHERE status=\'active\';\\""],\n    capture_output=True, text=True\n)\nactive_users = int(result.stdout.strip())\n\nresult = subprocess.run(\n    [\'su\', \'-\', \'postgres\', \'-c\',\n     "psql -d production_db -t -c \\"SELECT COUNT(*) FROM transactions;\\""],\n    capture_output=True, text=True\n)\ntotal_transactions = int(result.stdout.strip())\n\nresult = subprocess.run(\n    [\'su\', \'-\', \'postgres\', \'-c\',\n     "psql -d production_db -t -c \\"SELECT SUM(amount) FROM transactions;\\""],\n    capture_output=True, text=True\n)\ntotal_amount = float(result.stdout.strip())\n\nresult = subprocess.run(\n    [\'su\', \'-\', \'postgres\', \'-c\',\n     "psql -d production_db -t -c \\"SELECT AVG(total) FROM (SELECT user_id, SUM(amount) as total FROM transactions GROUP BY user_id) as user_totals;\\""],\n    capture_output=True, text=True\n)\navg_per_user = float(result.stdout.strip())\n\n# Write statistics report\nwith open(\'/backup/db_stats.txt\', \'w\') as f:\n    f.write(\'DATABASE STATISTICS\\n\')\n    f.write(\'==================\\n\')\n    f.write(f\'Total Users: {total_users}\\n\')\n    f.write(f\'Active Users: {active_users}\\n\')\n    f.write(f\'Total Transactions: {total_transactions}\\n\')\n    f.write(f\'Total Amount: {total_amount:.2f}\\n\')\n    f.write(f\'Average per User: {avg_per_user:.2f}\\n\')\n\nprint(\'Database statistics report generated\')\nEOF\n'
''
'cat /backup/db_stats.txt\n'
'python3 << \'EOF\'\nimport subprocess\n\n# Generate top users report\nresult = subprocess.run(\n    [\'su\', \'-\', \'postgres\', \'-c\',\n     "psql -d production_db -t -A -F\',\' -c \\"SELECT u.username, ROUND(SUM(t.amount)::numeric, 2) as total_amount FROM users u JOIN transactions t ON u.user_id = t.user_id GROUP BY u.username ORDER BY total_amount DESC, u.username ASC LIMIT 10;\\""],\n    capture_output=True, text=True\n)\n\n# Write top users report\nwith open(\'/backup/top_users.csv\', \'w\') as f:\n    f.write(\'username,total_amount\\n\')\n    f.write(result.stdout)\n\nprint(\'Top users report generated\')\nEOF\n'
'cat /backup/top_users.csv\n'
'su - postgres -c "psql -d production_db -c \'SELECT COUNT(*) FROM transactions;\'"\n'
'tail -20 /backup/import_transactions.sql\n'
'wc -l /backup/import_transactions.sql\n'
'su - postgres -c "psql -d production_db -c \'TRUNCATE transactions;\'"\n'
'su - postgres -c "psql -d production_db -f /backup/import_transactions.sql" > /tmp/import.log 2>&1\n'
'su - postgres -c "psql -d production_db -c \'SELECT COUNT(*) FROM transactions;\'"\n'
'python3 << \'EOF\'\nimport subprocess\n\n# Generate database statistics report\nresult = subprocess.run(\n    [\'su\', \'-\', \'postgres\', \'-c\', \n     "psql -d production_db -t -c \\"SELECT COUNT(*) FROM users;\\""],\n    capture_output=True, text=True\n)\ntotal_users = int(result.stdout.strip())\n\nresult = subprocess.run(\n    [\'su\', \'-\', \'postgres\', \'-c\',\n     "psql -d production_db -t -c \\"SELECT COUNT(*) FROM users WHERE status=\'active\';\\""],\n    capture_output=True, text=True\n)\nactive_users = int(result.stdout.strip())\n\nresult = subprocess.run(\n    [\'su\', \'-\', \'postgres\', \'-c\',\n     "psql -d production_db -t -c \\"SELECT COUNT(*) FROM transactions;\\""],\n    capture_output=True, text=True\n)\ntotal_transactions = int(result.stdout.strip())\n\nresult = subprocess.run(\n    [\'su\', \'-\', \'postgres\', \'-c\',\n     "psql -d production_db -t -c \\"SELECT SUM(amount) FROM transactions;\\""],\n    capture_output=True, text=True\n)\ntotal_amount = float(result.stdout.strip())\n\nresult = subprocess.run(\n    [\'su\', \'-\', \'postgres\', \'-c\',\n     "psql -d production_db -t -c \\"SELECT AVG(total) FROM (SELECT user_id, SUM(amount) as total FROM transactions GROUP BY user_id) as user_totals;\\""],\n    capture_output=True, text=True\n)\navg_per_user = float(result.stdout.strip())\n\n# Write statistics report\nwith open(\'/backup/db_stats.txt\', \'w\') as f:\n    f.write(\'DATABASE STATISTICS\\n\')\n    f.write(\'==================\\n\')\n    f.write(f\'Total Users: {total_users}\\n\')\n    f.write(f\'Active Users: {active_users}\\n\')\n    f.write(f\'Total Transactions: {total_transactions}\\n\')\n    f.write(f\'Total Amount: {total_amount:.2f}\\n\')\n    f.write(f\'Average per User: {avg_per_user:.2f}\\n\')\n\nprint(\'Database statistics report regenerated\')\nEOF\n'
'python3 << \'EOF\'\nimport subprocess\n\n# Generate top users report\nresult = subprocess.run(\n    [\'su\', \'-\', \'postgres\', \'-c\',\n     "psql -d production_db -t -A -F\',\' -c \\"SELECT u.username, ROUND(SUM(t.amount)::numeric, 2) as total_amount FROM users u JOIN transactions t ON u.user_id = t.user_id GROUP BY u.username ORDER BY total_amount DESC, u.username ASC LIMIT 10;\\""],\n    capture_output=True, text=True\n)\n\n# Write top users report\nwith open(\'/backup/top_users.csv\', \'w\') as f:\n    f.write(\'username,total_amount\\n\')\n    f.write(result.stdout)\n\nprint(\'Top users report regenerated\')\nEOF\n'
''
'cat /backup/db_stats.txt\n'
'cat /backup/top_users.csv\n'
'cat /backup/backup_metadata.log\n'
"python3 << 'EOF'\n# Generate backup verification report\nwith open('/backup/backup_verification.txt', 'w') as f:\n    f.write('BACKUP VERIFICATION\\n')\n    f.write('===================\\n')\n    f.write('Backup Date: 2025-09-28 03:00:00\\n')\n    f.write('Tables Backed Up: 2\\n')\n    f.write('Total Rows: 130\\n')\n    f.write('Integrity Check: PASSED\\n')\n\nprint('Backup verification report created')\nEOF\n"
"echo 'RECOVERY_SUCCESSFUL' > /backup/recovery_complete.txt\n"
'ls -la /backup/*.txt /backup/*.csv /backup/*.json\n'
'cat /backup/backup_verification.txt\n'
'cat /backup/recovery_complete.txt\n'
'tail -5 /backup/clean_users.csv\n'
'tail -5 /backup/valid_transactions.json\n'
'su - postgres -c "psql -d production_db -c \'SELECT COUNT(*) as user_count FROM users; SELECT COUNT(*) as txn_count FROM transactions;\'"\n'
'for file in /backup/backup_verification.txt /backup/recovery_complete.txt /backup/db_stats.txt /backup/top_users.csv /backup/clean_users.csv /backup/valid_transactions.json; do echo "Checking $file:"; tail -c 1 "$file" | od -An -tx1; done\n'
"echo '=== Final Verification ==='\n"
'echo \'Database tables:\' && su - postgres -c "psql -d production_db -c \'\\\\dt\'"\n'
'echo \'Row counts:\' && su - postgres -c "psql -d production_db -c \'SELECT (SELECT COUNT(*) FROM users) as users, (SELECT COUNT(*) FROM transactions) as transactions;\'"\n'
"echo '=== FINAL REQUIREMENTS CHECK ===' && echo ''\n"
'echo \'1. Database and Tables:\' && su - postgres -c "psql -d production_db -c \'SELECT tablename FROM pg_tables WHERE schemaname = \'"\'"\'public\'"\'"\';\'"\n'
"echo '2. Files Created:' && ls -1 /backup/*.txt /backup/clean_users.csv /backup/top_users.csv /backup/valid_transactions.json 2>/dev/null | xargs -n1 basename\n"
"echo '3. Sample Data Check - Top Users (first 3):' && head -4 /backup/top_users.csv\n"
"echo '4. Database Stats:' && cat /backup/db_stats.txt\n"
"echo '5. Recovery Status:' && cat /backup/recovery_complete.txt && echo 'All tasks completed successfully!'\n"
'su - postgres -c "psql -d production_db -c \'\\\\dt\'"\n'
"echo 'Verification Summary:' && echo '- production_db database: CREATED' && echo '- users table with 30 rows: IMPORTED' && echo '- transactions table with 100 rows: IMPORTED' && echo '- clean_users.csv: CREATED' && echo '- valid_transactions.json: CREATED' && echo '- db_stats.txt: CREATED' && echo '- top_users.csv: CREATED' && echo '- backup_verification.txt: CREATED' && echo '- recovery_complete.txt: CREATED' && echo '' && echo 'ALL TASKS COMPLETED SUCCESSFULLY!'\n"
['asciinema rec --stdin /logs/tests.cast', 'Enter']
['clear', 'Enter']
['bash ', '/tests/run-tests.sh', 'Enter']
['C-d']
['C-d']

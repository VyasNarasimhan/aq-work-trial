root@74009b1efc62:/backup# ls -la /backup/; tmux wait -S done
total 40
drwxr-xr-x 1 root root  4096 Dec  4 16:59 .
drwxr-xr-x 1 root root  4096 Dec  4 17:54 ..
-rw-r--r-- 1 root root   945 Dec  4 16:54 backup_metadata.log
-rw-r--r-- 1 root root   718 Dec  4 16:54 database.sql
-rw-r--r-- 1 root root   703 Dec  4 16:54 postgresql.conf
-rw-r--r-- 1 root root 15425 Dec  4 16:54 transactions_backup.json
-rw-r--r-- 1 root root  2351 Dec  4 16:54 users_export.csv
root@74009b1efc62:/backup# service postgresql start; tmux wait -S done
 * Starting PostgreSQL 16 database server                                                                                                                [ OK ]
root@74009b1efc62:/backup# head -20 /backup/database.sql; tmux wait -S done
-- PostgreSQL database dump
-- This dump contains the schema and some sample data
-- Note: Some statements may have errors that need to be fixed

-- Create users table
CREATE TABLE IF NOT EXISTS users (
    user_id INTEGER PRIMARY KEY,
    username VARCHAR(100) NOT NULL,
    email VARCHAR(255) NOT NULL,
    created_at TIMESTAMP,
    status VARCHAR(20)
);

-- Create transactions table
CREATE TABLE IF NOT EXISTS transactions (
    transaction_id INTEGER PRIMARY KEY,
    user_id INTEGER,
    amount DECIMAL(10,2),
    timestamp TIMESTAMP,
    description TEXT,
root@74009b1efc62:/backup# head -20 /backup/users_export.csv; tmux wait -S done
user_id,username,email,created_at,status
1,alice_smith,alice_smith@example.com,2024-11-21 01:25:46,inactive
2,bob_jones,bob_jones@example.com,2025-06-28 01:25:46,active
3,charlie_brown,charlie_brown@example.com,2025-08-13 01:25:46,suspended
4,diana_prince,diana_prince@example.com,2025-08-05 01:25:46,inactive
5,eve_adams,eve_adams@example.com,2025-09-08 01:25:46,inactive
6,frank_white,frank_white@example.com,2025-09-04 01:25:46,active
7,grace_lee,grace_lee@example.com,2025-06-05 01:25:46,active
8,henry_ford,henry_ford@example.com,2025-07-25 01:25:46,inactive
9,iris_west,iris_west@example.com,2025-03-23 01:25:46,suspended
10,jack_ryan,jack_ryan@example.com,2024-10-19 01:25:46,inactive
11,kate_mills,kate_mills@example.com,2025-06-27 01:25:46,active
12,leo_king,leo_king@example.com,2024-12-21 01:25:46,inactive
13,mary_jane,mary_jane@example.com,2025-10-03 01:25:46,suspended
14,nick_fury,nick_fury@example.com,2025-04-03 01:25:46,suspended
15,olivia_pope,olivia_pope@example.com,2025-06-01 01:25:46,active
16,peter_parker,peter_parker@example.com,2025-01-02 01:25:46,inactive
17,quinn_baker,quinn_baker@example.com,2025-01-22 01:25:46,suspended
18,rachel_green,rachel_green@example.com,2025-04-01 01:25:46,inactive
19,steve_rogers,steve_rogers@example.com,2025-06-28 01:25:46,active
root@74009b1efc62:/backup# head -20 /backup/transactions_backup.json; tmux wait -S done
[
  {
    "transaction_id": 1,
    "user_id": 16,
    "amount": 46.0,
    "timestamp": "2025-07-16 01:25:56",
    "description": "Subscription"
  },
  {
    "transaction_id": 2,
    "user_id": 6,
    "amount": 646.05,
    "timestamp": "2025-05-02 01:25:56",
    "description": "Payment"
  },
  {
    "transaction_id": 3,
    "user_id": 29,
    "amount": 186.76,
    "timestamp": "2025-07-30 01:25:56",
root@74009b1efc62:/backup# cat /backup/backup_metadata.log; tmux wait -S done
[2025-09-28 03:00:00] INFO: Starting database backup process
[2025-09-28 03:00:01] INFO: Backup initiated by: admin
[2025-09-28 03:00:01] INFO: Backup type: Full
[2025-09-28 03:00:02] INFO: Connecting to database: production_db
[2025-09-28 03:00:03] INFO: Connection successful
[2025-09-28 03:00:05] INFO: Backing up table: users
[2025-09-28 03:00:06] INFO: Table 'users' backed up successfully - 30 rows
[2025-09-28 03:00:07] INFO: Backing up table: transactions
[2025-09-28 03:00:09] INFO: Table 'transactions' backed up successfully - 100 rows
[2025-09-28 03:00:10] INFO: Total tables backed up: 2
[2025-09-28 03:00:10] INFO: Total rows backed up: 130
[2025-09-28 03:00:11] INFO: Running integrity check
[2025-09-28 03:00:12] INFO: Integrity check: PASSED
[2025-09-28 03:00:13] INFO: Backup completed successfully
[2025-09-28 03:00:13] INFO: Backup file: /backup/database.sql
[2025-09-28 03:00:13] INFO: Backup timestamp: 2025-09-28 03:00:00
root@74009b1efc62:/backup# psql -U postgres -c 'CREATE DATABASE production_db;'; tmux wait -S done
psql: error: connection to server on socket "/var/run/postgresql/.s.PGSQL.5432" failed: FATAL:  Peer authentication failed for user "postgres"
root@74009b1efc62:/backup# psql -U postgres -d production_db -f /backup/database.sql; tmux wait -S done
psql: error: connection to server on socket "/var/run/postgresql/.s.PGSQL.5432" failed: FATAL:  Peer authentication failed for user "postgres"
root@74009b1efc62:/backup# psql -U postgres -d production_db -c '\dt'; tmux wait -S done
psql: error: connection to server on socket "/var/run/postgresql/.s.PGSQL.5432" failed: FATAL:  Peer authentication failed for user "postgres"
root@74009b1efc62:/backup# su - postgres; tmux wait -S done
postgres@74009b1efc62:~$ createdb production_db; tmux wait -S done
error connecting to /tmp/tmux-100/default (No such file or directory)
postgres@74009b1efc62:~$ psql -d production_db -f /backup/database.sql
CREATE TABLE
CREATE TABLE
postgres@74009b1efc62:~$ psql -d production_db -c '\dt'
            List of relations
 Schema |     Name     | Type  |  Owner
--------+--------------+-------+----------
 public | transactions | table | postgres
 public | users        | table | postgres
(2 rows)

postgres@74009b1efc62:~$ exit
logout
root@74009b1efc62:/backup# wc -l /backup/users_export.csv; tmux wait -S done
37 /backup/users_export.csv
root@74009b1efc62:/backup# cat /backup/users_export.csv; tmux wait -S done
user_id,username,email,created_at,status
1,alice_smith,alice_smith@example.com,2024-11-21 01:25:46,inactive
2,bob_jones,bob_jones@example.com,2025-06-28 01:25:46,active
3,charlie_brown,charlie_brown@example.com,2025-08-13 01:25:46,suspended
4,diana_prince,diana_prince@example.com,2025-08-05 01:25:46,inactive
5,eve_adams,eve_adams@example.com,2025-09-08 01:25:46,inactive
6,frank_white,frank_white@example.com,2025-09-04 01:25:46,active
7,grace_lee,grace_lee@example.com,2025-06-05 01:25:46,active
8,henry_ford,henry_ford@example.com,2025-07-25 01:25:46,inactive
9,iris_west,iris_west@example.com,2025-03-23 01:25:46,suspended
10,jack_ryan,jack_ryan@example.com,2024-10-19 01:25:46,inactive
11,kate_mills,kate_mills@example.com,2025-06-27 01:25:46,active
12,leo_king,leo_king@example.com,2024-12-21 01:25:46,inactive
13,mary_jane,mary_jane@example.com,2025-10-03 01:25:46,suspended
14,nick_fury,nick_fury@example.com,2025-04-03 01:25:46,suspended
15,olivia_pope,olivia_pope@example.com,2025-06-01 01:25:46,active
16,peter_parker,peter_parker@example.com,2025-01-02 01:25:46,inactive
17,quinn_baker,quinn_baker@example.com,2025-01-22 01:25:46,suspended
18,rachel_green,rachel_green@example.com,2025-04-01 01:25:46,inactive
19,steve_rogers,steve_rogers@example.com,2025-06-28 01:25:46,active
20,tony_stark,tony_stark@example.com,2025-07-18 01:25:46,suspended
21,uma_thurman,uma_thurman@example.com,2025-01-13 01:25:46,active
22,victor_von,victor_von@example.com,2024-10-17 01:25:46,active
23,wade_wilson,wade_wilson@example.com,2025-04-24 01:25:46,suspended
24,xavier_prof,xavier_prof@example.com,2025-09-27 01:25:46,inactive
25,yara_greyjoy,yara_greyjoy@example.com,2025-06-21 01:25:46,active
26,zara_ahmed,zara_ahmed@example.com,2025-09-19 01:25:46,active
27,alan_turing,alan_turing@example.com,2025-03-17 01:25:46,inactive
28,betty_white,betty_white@example.com,2024-10-09 01:25:46,active
29,clark_kent,clark_kent@example.com,2025-09-22 01:25:46,active
30,donna_noble,donna_noble@example.com,2024-11-22 01:25:46,active
,bad_user1,bad1@example.com,2024-01-01 10:00:00,active
31,bad_user2,bademail.com,2024-01-01 10:00:00,active
32,,bad3@example.com,2024-01-01 10:00:00,active
33,bad_user4,bad4@example.com,2024-01-01 10:00:00,deleted
34,bad_user5,,2024-01-01 10:00:00,active
,,noemail,2024-01-01 10:00:00,invalid
root@74009b1efc62:/backup# python3 -c "import json; data=json.load(open('/backup/transactions_backup.json')); print(f'Total transactions: {len(data)}'); print('
First 5:'); import pprint; pprint.pprint(data[:5])"; tmux wait -S done
Total transactions: 106
First 5:
[{'amount': 46.0,
  'description': 'Subscription',
  'timestamp': '2025-07-16 01:25:56',
  'transaction_id': 1,
  'user_id': 16},
 {'amount': 646.05,
  'description': 'Payment',
  'timestamp': '2025-05-02 01:25:56',
  'transaction_id': 2,
  'user_id': 6},
 {'amount': 186.76,
  'description': 'Payment',
  'timestamp': '2025-07-30 01:25:56',
  'transaction_id': 3,
  'user_id': 29},
 {'amount': 757.37,
  'description': 'Deposit',
  'timestamp': '2025-09-03 01:25:56',
  'transaction_id': 4,
  'user_id': 10},
 {'amount': 366.3,
  'description': 'Refund',
  'timestamp': '2025-09-21 01:25:56',
  'transaction_id': 5,
  'user_id': 9}]
root@74009b1efc62:/backup# python3 -c "import json; data=json.load(open('/backup/transactions_backup.json')); print('Last 10:'); import pprint; pprint.pprint(da
ta[-10:])"; tmux wait -S done
Last 10:
[{'amount': 195.0,
  'description': 'Transfer',
  'timestamp': '2025-08-26 01:25:56',
  'transaction_id': 97,
  'user_id': 20},
 {'amount': 544.03,
  'description': 'Subscription',
  'timestamp': '2025-08-12 01:25:56',
  'transaction_id': 98,
  'user_id': 13},
 {'amount': 591.71,
  'description': 'Purchase',
  'timestamp': '2025-08-12 01:25:56',
  'transaction_id': 99,
  'user_id': 26},
 {'amount': 372.72,
  'description': 'Subscription',
  'timestamp': '2025-07-05 01:25:56',
  'transaction_id': 100,
  'user_id': 2},
 {'amount': 100.0,
  'description': 'Invalid',
  'timestamp': '2024-01-01 10:00:00',
  'transaction_id': None,
  'user_id': 5},
 {'amount': -50.0,
  'description': 'Invalid',
  'timestamp': '2024-01-01 10:00:00',
  'transaction_id': 101,
  'user_id': 10},
 {'amount': 200.0,
  'description': 'Invalid',
  'timestamp': None,
  'transaction_id': 102,
  'user_id': 15},
 {'amount': 150.0,
  'description': 'Invalid',
  'timestamp': '2024-01-01 10:00:00',
  'transaction_id': 103,
  'user_id': 999},
 {'amount': 0,
  'description': 'Invalid',
  'timestamp': '2024-01-01 10:00:00',
  'transaction_id': 104,
  'user_id': 8},
 {'amount': 'invalid',
  'description': 'Invalid',
  'timestamp': '2024-01-01 10:00:00',
  'transaction_id': 105,
  'user_id': 12}]
root@74009b1efc62:/backup# cat > /backup/clean_and_import.py << 'EOF'
> #!/usr/bin/env python3
> import csv
> import json
> import re
> import subprocess
>
> # Clean users CSV
> print("Cleaning users CSV...")
> valid_users = []
> with open('/backup/users_export.csv', 'r') as f:
>     reader = csv.DictReader(f)
>     for row in reader:
>         # Check if user_id exists and is not empty
>         if not row.get('user_id') or row['user_id'].strip() == '':
>             continue
>         # Check if username is not empty
>         if not row.get('username') or row['username'].strip() == '':
>             continue
>         # Check if email contains @
>         if not row.get('email') or '@' not in row['email']:
>             continue
>         # Check if status is valid
>         if row.get('status') not in ['active', 'inactive', 'suspended']:
>             continue
>         valid_users.append(row)
>
> # Write cleaned users to CSV
> with open('/backup/clean_users.csv', 'w', newline='') as f:
>     writer = csv.DictWriter(f, fieldnames=['user_id', 'username', 'email', 'created_at', 'status'])
>     writer.writeheader()
>     writer.writerows(valid_users)
>
> print(f"Cleaned users: {len(valid_users)} valid records")
>
> # Clean transactions JSON
> print("Cleaning transactions JSON...")
> with open('/backup/transactions_backup.json', 'r') as f:
>     transactions = json.load(f)
>
> valid_transactions = []
> for txn in transactions:
>     # Check transaction_id is not null
>     if txn.get('transaction_id') is None:
>         continue
>     # Check amount is valid (positive number)
>     try:
>         amount = float(txn.get('amount', 0))
>         if amount <= 0:
>             continue
>     except (ValueError, TypeError):
>         continue
>     # Check timestamp is not null
>     if not txn.get('timestamp'):
>         continue
>     # Check user_id is in valid range (1-30)
>     try:
>         user_id = int(txn.get('user_id', 0))
>         if user_id < 1 or user_id > 30:
>             continue
>     except (ValueError, TypeError):
>         continue
>     valid_transactions.append(txn)
>
> # Write cleaned transactions to JSON
> with open('/backup/valid_transactions.json', 'w') as f:
>     json.dump(valid_transactions, f)
>     f.write('\n')
>
> print(f"Cleaned transactions: {len(valid_transactions)} valid records")
>
> print("Data cleaning complete!")
> EOF
root@74009b1efc62:/backup# chmod +x /backup/clean_and_import.py; tmux wait -S done
root@74009b1efc62:/backup# python3 /backup/clean_and_import.py; tmux wait -S done
Cleaning users CSV...
Cleaned users: 30 valid records
Cleaning transactions JSON...
Cleaned transactions: 100 valid records
Data cleaning complete!
root@74009b1efc62:/backup# head -5 /backup/clean_users.csv; tmux wait -S done
user_id,username,email,created_at,status
1,alice_smith,alice_smith@example.com,2024-11-21 01:25:46,inactive
2,bob_jones,bob_jones@example.com,2025-06-28 01:25:46,active
3,charlie_brown,charlie_brown@example.com,2025-08-13 01:25:46,suspended
4,diana_prince,diana_prince@example.com,2025-08-05 01:25:46,inactive
root@74009b1efc62:/backup# wc -l /backup/clean_users.csv; tmux wait -S done
31 /backup/clean_users.csv
root@74009b1efc62:/backup# cat > /backup/import_and_report.py << 'EOF'
> #!/usr/bin/env python3
> import csv
> import json
> import subprocess
> import sys
>
> # Import users into database
> print("Importing users into database...")
> with open('/backup/clean_users.csv', 'r') as f:
>     reader = csv.DictReader(f)
>     users = list(reader)
>
> # Create SQL for users import
> user_values = []
> for user in users:
>     user_values.append(f"({user['user_id']}, '{user['username']}', '{user['email']}', '{user['created_at']}', '{user['status']}')")
te!")
EOF
>
> users_sql = f"INSERT INTO users (user_id, username, email, created_at, status) VALUES {','.join(user_values)};"
>
> # Import transactions into database
> print("Importing transactions into database...")
> with open('/backup/valid_transactions.json', 'r') as f:
>     transactions = json.load(f)
>
> txn_values = []
> for txn in transactions:
>     desc = txn['description'].replace("'", "''")
>     txn_values.append(f"({txn['transaction_id']}, {txn['user_id']}, {txn['amount']}, '{txn['timestamp']}', '{desc}')")
>
> txns_sql = f"INSERT INTO transactions (transaction_id, user_id, amount, timestamp, description) VALUES {','.join(txn_values)};"
>
> # Execute SQL as postgres user
> subprocess.run(['su', '-', 'postgres', '-c', f"psql -d production_db -c \"{users_sql}\""], check=True)
> subprocess.run(['su', '-', 'postgres', '-c', f"psql -d production_db -c \"{txns_sql}\""], check=True)
>
> print("Data import complete!")
>
> # Generate database statistics report
> print("Generating database statistics...")
> stats_queries = [
>     ("Total Users", "SELECT COUNT(*) FROM users;"),
>     ("Active Users", "SELECT COUNT(*) FROM users WHERE status = 'active';"),
>     ("Total Transactions", "SELECT COUNT(*) FROM transactions;"),
>     ("Total Amount", "SELECT ROUND(SUM(amount)::numeric, 2) FROM transactions;"),
>     ("Average per User", "SELECT ROUND(AVG(total)::numeric, 2) FROM (SELECT user_id, SUM(amount) as total FROM transactions GROUP BY user_id) as user_totals;"
)
> ]
>
> stats = {}
> for label, query in stats_queries:
>     result = subprocess.run(
>         ['su', '-', 'postgres', '-c', f'psql -d production_db -t -c "{query}"'],
>         capture_output=True, text=True, check=True
>     )
>     stats[label] = result.stdout.strip()
>
> with open('/backup/db_stats.txt', 'w') as f:
>     f.write("DATABASE STATISTICS\n")
>     f.write("==================\n")
>     f.write(f"Total Users: {stats['Total Users']}\n")
>     f.write(f"Active Users: {stats['Active Users']}\n")
>     f.write(f"Total Transactions: {stats['Total Transactions']}\n")
>     f.write(f"Total Amount: {stats['Total Amount']}\n")
>     f.write(f"Average per User: {stats['Average per User']}\n")
>
> print("Database statistics report generated!")
>
> # Generate top users report
> print("Generating top users report...")
> top_query = """SELECT u.username, ROUND(SUM(t.amount)::numeric, 2) as total_amount
> FROM users u
> JOIN transactions t ON u.user_id = t.user_id
> GROUP BY u.username
> ORDER BY total_amount DESC, u.username ASC
> LIMIT 10;"""
>
> result = subprocess.run(
>     ['su', '-', 'postgres', '-c', f'psql -d production_db -t -A -F"," -c "{top_query}"'],
>     capture_output=True, text=True, check=True
> )
>
> with open('/backup/top_users.csv', 'w') as f:
>     f.write("username,total_amount\n")
>     f.write(result.stdout)
>
> print("Top users report generated!")
>
> # Generate backup verification report
> print("Generating backup verification report...")
> with open('/backup/backup_metadata.log', 'r') as f:
>     log_content = f.read()
>
> # Extract information from log
> backup_date = ''
> tables_backed_up = ''
> total_rows = ''
> integrity_check = ''
>
> for line in log_content.split('\n'):
>     if 'Backup timestamp:' in line:
>         backup_date = line.split('Backup timestamp:')[1].strip()
>     elif 'Total tables backed up:' in line:
>         tables_backed_up = line.split('Total tables backed up:')[1].strip()
>     elif 'Total rows backed up:' in line:
>         total_rows = line.split('Total rows backed up:')[1].strip()
>     elif 'Integrity check:' in line:
>         integrity_check = line.split('Integrity check:')[1].strip()
>
> with open('/backup/backup_verification.txt', 'w') as f:
>     f.write("BACKUP VERIFICATION\n")
>     f.write("===================\n")
>     f.write(f"Backup Date: {backup_date}\n")
>     f.write(f"Tables Backed Up: {tables_backed_up}\n")
>     f.write(f"Total Rows: {total_rows}\n")
>     f.write(f"Integrity Check: {integrity_check}\n")
>
> print("Backup verification report generated!")
>
> # Create recovery completion marker
> with open('/backup/recovery_complete.txt', 'w') as f:
>     f.write("RECOVERY_SUCCESSFUL\n")
>
> print("Recovery complete!")
> EOF
root@74009b1efc62:/backup# chmod +x /backup/import_and_report.py; tmux wait -S done
root@74009b1efc62:/backup# python3 /backup/import_and_report.py; tmux wait -S done
Importing users into database...
Importing transactions into database...
INSERT 0 30
INSERT 0 100
Data import complete!
Generating database statistics...
Database statistics report generated!
Generating top users report...
Top users report generated!
Generating backup verification report...
Backup verification report generated!
Recovery complete!
root@74009b1efc62:/backup# ls -la /backup/*.txt /backup/*.csv /backup/*.json; tmux wait -S done
-rw-r--r-- 1 root root   133 Dec  4 17:56 /backup/backup_verification.txt
-rw-r--r-- 1 root root  2052 Dec  4 17:55 /backup/clean_users.csv
-rw-r--r-- 1 root root   145 Dec  4 17:56 /backup/db_stats.txt
-rw-r--r-- 1 root root    20 Dec  4 17:56 /backup/recovery_complete.txt
-rw-r--r-- 1 root root   219 Dec  4 17:56 /backup/top_users.csv
-rw-r--r-- 1 root root 15425 Dec  4 16:54 /backup/transactions_backup.json
-rw-r--r-- 1 root root  2351 Dec  4 16:54 /backup/users_export.csv
-rw-r--r-- 1 root root 11971 Dec  4 17:55 /backup/valid_transactions.json
root@74009b1efc62:/backup# cat /backup/db_stats.txt; tmux wait -S done
DATABASE STATISTICS
==================
Total Users: 30
Active Users: 13
Total Transactions: 100
Total Amount: 53109.46
Average per User: 1770.32
root@74009b1efc62:/backup# cat /backup/backup_verification.txt; tmux wait -S done
BACKUP VERIFICATION
===================
Backup Date: 2025-09-28 03:00:00
Tables Backed Up: 2
Total Rows: 130
Integrity Check: PASSED
root@74009b1efc62:/backup# cat /backup/top_users.csv; tmux wait -S done
username,total_amount
zara_ahmed,4400.17
alice_smith,3682.87
victor_von,3451.21
donna_noble,3225.49
xavier_prof,2990.51
nick_fury,2709.20
wade_wilson,2678.95
tony_stark,2637.00
frank_white,2539.97
charlie_brown,2525.32
root@74009b1efc62:/backup# cat /backup/recovery_complete.txt; tmux wait -S done
RECOVERY_SUCCESSFUL
root@74009b1efc62:/backup# su - postgres -c "psql -d production_db -c 'SELECT COUNT(*) FROM users;'"; tmux wait -S done
 count
-------
    30
(1 row)

root@74009b1efc62:/backup# su - postgres -c "psql -d production_db -c 'SELECT COUNT(*) FROM transactions;'"; tmux wait -S done
 count
-------
   100
(1 row)

root@74009b1efc62:/backup# tail -c 20 /backup/clean_users.csv | od -c; tmux wait -S done
0000000   2   2       0   1   :   2   5   :   4   6   ,   a   c   t   i
0000020   v   e  \r  \n
0000024
root@74009b1efc62:/backup# tail -c 20 /backup/valid_transactions.json | od -c; tmux wait -S done
0000000   "   :       "   S   u   b   s   c   r   i   p   t   i   o   n
0000020   "   }   ]  \n
0000024
root@74009b1efc62:/backup# tail -c 20 /backup/db_stats.txt | od -c; tmux wait -S done
0000000   e       p   e   r       U   s   e   r   :       1   7   7   0
0000020   .   3   2  \n
0000024
root@74009b1efc62:/backup# tail -c 20 /backup/top_users.csv | od -c; tmux wait -S done
0000000   a   r   l   i   e   _   b   r   o   w   n   ,   2   5   2   5
0000020   .   3   2  \n
0000024
root@74009b1efc62:/backup# tail -c 20 /backup/backup_verification.txt | od -c; tmux wait -S done
0000000   g   r   i   t   y       C   h   e   c   k   :       P   A   S
0000020   S   E   D  \n
0000024
root@74009b1efc62:/backup# tail -c 20 /backup/recovery_complete.txt | od -c; tmux wait -S done
0000000   R   E   C   O   V   E   R   Y   _   S   U   C   C   E   S   S
0000020   F   U   L  \n
0000024
root@74009b1efc62:/backup# dos2unix /backup/clean_users.csv 2>/dev/null || sed -i 's/\r$//' /backup/clean_users.csv; tmux wait -S done
root@74009b1efc62:/backup# tail -c 20 /backup/clean_users.csv | od -c; tmux wait -S done
0000000   -   2   2       0   1   :   2   5   :   4   6   ,   a   c   t
0000020   i   v   e  \n
0000024
root@74009b1efc62:/backup# su - postgres -c "psql -d production_db -c '\d users'"; tmux wait -S done
                           Table "public.users"
   Column   |            Type             | Collation | Nullable | Default
------------+-----------------------------+-----------+----------+---------
 user_id    | integer                     |           | not null |
 username   | character varying(100)      |           | not null |
 email      | character varying(255)      |           | not null |
 created_at | timestamp without time zone |           |          |
 status     | character varying(20)       |           |          |
Indexes:
    "users_pkey" PRIMARY KEY, btree (user_id)
Referenced by:
    TABLE "transactions" CONSTRAINT "transactions_user_id_fkey" FOREIGN KEY (user_id) REFERENCES users(user_id)

root@74009b1efc62:/backup# su - postgres -c "psql -d production_db -c '\d transactions'"; tmux wait -S done
                          Table "public.transactions"
     Column     |            Type             | Collation | Nullable | Default
----------------+-----------------------------+-----------+----------+---------
 transaction_id | integer                     |           | not null |
 user_id        | integer                     |           |          |
 amount         | numeric(10,2)               |           |          |
 timestamp      | timestamp without time zone |           |          |
 description    | text                        |           |          |
Indexes:
    "transactions_pkey" PRIMARY KEY, btree (transaction_id)
Foreign-key constraints:
    "transactions_user_id_fkey" FOREIGN KEY (user_id) REFERENCES users(user_id)

root@74009b1efc62:/backup# ls -1 /backup/*.txt /backup/*.csv /backup/*.json | grep -E '(clean_users|valid_transactions|db_stats|top_users|backup_verification|re
covery_complete)'; tmux wait -S done
/backup/backup_verification.txt
/backup/clean_users.csv
/backup/db_stats.txt
/backup/recovery_complete.txt
/backup/top_users.csv
/backup/valid_transactions.json
root@74009b1efc62:/backup# echo 'All tasks completed successfully!'; tmux wait -S done
All tasks completed successfully!
root@74009b1efc62:/backup# echo 'Recovery process completed successfully. All files generated and database restored.'; tmux wait -S done
Recovery process completed successfully. All files generated and database restored.
root@74009b1efc62:/backup#

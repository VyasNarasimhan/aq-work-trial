root@5dedd0e6de41:/backup# ls -la /backup/; tmux wait -S done
total 40
drwxr-xr-x 1 root root  4096 Dec  4 16:59 .
drwxr-xr-x 1 root root  4096 Dec  4 17:54 ..
-rw-r--r-- 1 root root   945 Dec  4 16:54 backup_metadata.log
-rw-r--r-- 1 root root   718 Dec  4 16:54 database.sql
-rw-r--r-- 1 root root   703 Dec  4 16:54 postgresql.conf
-rw-r--r-- 1 root root 15425 Dec  4 16:54 transactions_backup.json
-rw-r--r-- 1 root root  2351 Dec  4 16:54 users_export.csv
root@5dedd0e6de41:/backup# service postgresql start; tmux wait -S done
 * Starting PostgreSQL 16 database server                                                                                                                [ OK ]
root@5dedd0e6de41:/backup# cat /backup/backup_metadata.log; tmux wait -S done
[2025-09-28 03:00:00] INFO: Starting database backup process
[2025-09-28 03:00:01] INFO: Backup initiated by: admin
[2025-09-28 03:00:01] INFO: Backup type: Full
[2025-09-28 03:00:02] INFO: Connecting to database: production_db
[2025-09-28 03:00:03] INFO: Connection successful
[2025-09-28 03:00:05] INFO: Backing up table: users
[2025-09-28 03:00:06] INFO: Table 'users' backed up successfully - 30 rows
[2025-09-28 03:00:07] INFO: Backing up table: transactions
[2025-09-28 03:00:09] INFO: Table 'transactions' backed up successfully - 100 rows
[2025-09-28 03:00:10] INFO: Total tables backed up: 2
[2025-09-28 03:00:10] INFO: Total rows backed up: 130
[2025-09-28 03:00:11] INFO: Running integrity check
[2025-09-28 03:00:12] INFO: Integrity check: PASSED
[2025-09-28 03:00:13] INFO: Backup completed successfully
[2025-09-28 03:00:13] INFO: Backup file: /backup/database.sql
[2025-09-28 03:00:13] INFO: Backup timestamp: 2025-09-28 03:00:00
root@5dedd0e6de41:/backup# head -20 /backup/users_export.csv; tmux wait -S done
user_id,username,email,created_at,status
1,alice_smith,alice_smith@example.com,2024-11-21 01:25:46,inactive
2,bob_jones,bob_jones@example.com,2025-06-28 01:25:46,active
3,charlie_brown,charlie_brown@example.com,2025-08-13 01:25:46,suspended
4,diana_prince,diana_prince@example.com,2025-08-05 01:25:46,inactive
5,eve_adams,eve_adams@example.com,2025-09-08 01:25:46,inactive
6,frank_white,frank_white@example.com,2025-09-04 01:25:46,active
7,grace_lee,grace_lee@example.com,2025-06-05 01:25:46,active
8,henry_ford,henry_ford@example.com,2025-07-25 01:25:46,inactive
9,iris_west,iris_west@example.com,2025-03-23 01:25:46,suspended
10,jack_ryan,jack_ryan@example.com,2024-10-19 01:25:46,inactive
11,kate_mills,kate_mills@example.com,2025-06-27 01:25:46,active
12,leo_king,leo_king@example.com,2024-12-21 01:25:46,inactive
13,mary_jane,mary_jane@example.com,2025-10-03 01:25:46,suspended
14,nick_fury,nick_fury@example.com,2025-04-03 01:25:46,suspended
15,olivia_pope,olivia_pope@example.com,2025-06-01 01:25:46,active
16,peter_parker,peter_parker@example.com,2025-01-02 01:25:46,inactive
17,quinn_baker,quinn_baker@example.com,2025-01-22 01:25:46,suspended
18,rachel_green,rachel_green@example.com,2025-04-01 01:25:46,inactive
19,steve_rogers,steve_rogers@example.com,2025-06-28 01:25:46,active
root@5dedd0e6de41:/backup# head -20 /backup/transactions_backup.json; tmux wait -S done
[
  {
    "transaction_id": 1,
    "user_id": 16,
    "amount": 46.0,
    "timestamp": "2025-07-16 01:25:56",
    "description": "Subscription"
  },
  {
    "transaction_id": 2,
    "user_id": 6,
    "amount": 646.05,
    "timestamp": "2025-05-02 01:25:56",
    "description": "Payment"
  },
  {
    "transaction_id": 3,
    "user_id": 29,
    "amount": 186.76,
    "timestamp": "2025-07-30 01:25:56",
root@5dedd0e6de41:/backup# cat /backup/database.sql; tmux wait -S done
-- PostgreSQL database dump
-- This dump contains the schema and some sample data
-- Note: Some statements may have errors that need to be fixed

-- Create users table
CREATE TABLE IF NOT EXISTS users (
    user_id INTEGER PRIMARY KEY,
    username VARCHAR(100) NOT NULL,
    email VARCHAR(255) NOT NULL,
    created_at TIMESTAMP,
    status VARCHAR(20)
);

-- Create transactions table
CREATE TABLE IF NOT EXISTS transactions (
    transaction_id INTEGER PRIMARY KEY,
    user_id INTEGER,
    amount DECIMAL(10,2),
    timestamp TIMESTAMP,
    description TEXT,
    FOREIGN KEY (user_id) REFERENCES users(user_id)
);

-- Note: The data will be imported from CSV and JSON files
-- This dump only contains the schema
root@5dedd0e6de41:/backup# psql -U postgres -c "CREATE DATABASE production_db;"; tmux wait -S done
psql: error: connection to server on socket "/var/run/postgresql/.s.PGSQL.5432" failed: FATAL:  Peer authentication failed for user "postgres"
root@5dedd0e6de41:/backup# psql -U postgres -d production_db -f /backup/database.sql; tmux wait -S done
psql: error: connection to server on socket "/var/run/postgresql/.s.PGSQL.5432" failed: FATAL:  Peer authentication failed for user "postgres"
root@5dedd0e6de41:/backup# cat > /backup/clean_and_import.py << 'EOF'
> import csv
> import json
> import re
> import psycopg2
>
> # Clean users CSV
> valid_users = []
> with open('/backup/users_export.csv', 'r') as f:
>     reader = csv.DictReader(f)
>     for row in reader:
>         # Check for missing user_id
>         if not row.get('user_id') or not row['user_id'].strip():
>             continue
>         # Check for empty username
>         if not row.get('username') or not row['username'].strip():
>             continue
>         # Check for invalid email (must contain @)
>         if not row.get('email') or '@' not in row['email']:
>             continue
>         # Check for invalid status
>         status = row.get('status', '').strip()
>         if status not in ['active', 'inactive', 'suspended']:
>             continue
>         valid_users.append(row)
>
> # Write cleaned users to CSV
> with open('/backup/clean_users.csv', 'w', newline='') as f:
>     writer = csv.DictWriter(f, fieldnames=['user_id', 'username', 'email', 'created_at', 'status'])
>     writer.writeheader()
>     writer.writerows(valid_users)
>
> print(f"Cleaned {len(valid_users)} valid users")
>
> # Clean transactions JSON
> with open('/backup/transactions_backup.json', 'r') as f:
>     transactions = json.load(f)
>
> valid_transactions = []
> for txn in transactions:
>     # Check for null transaction_id
>     if txn.get('transaction_id') is None:
>         continue
>     # Check for null or negative amounts
>     amount = txn.get('amount')
>     if amount is None or amount <= 0:
>         continue
>     # Check for missing timestamp
>     if not txn.get('timestamp'):
>         continue
>     # Check for valid user_id (1-30)
>     user_id = txn.get('user_id')
>     if user_id is None or user_id < 1 or user_id > 30:
>         continue
>     valid_transactions.append(txn)
>
> # Write valid transactions to JSON
> with open('/backup/valid_transactions.json', 'w') as f:
>     json.dump(valid_transactions, f, indent=2)
>     f.write('\n')
>
> print(f"Cleaned {len(valid_transactions)} valid transactions")
>
> # Import into database
> conn = psycopg2.connect(
>     dbname='production_db',
>     user='postgres',
>     host='localhost'
> )
> cur = conn.cursor()
>
> # Import users
> for user in valid_users:
>     cur.execute(
>         "INSERT INTO users (user_id, username, email, created_at, status) VALUES (%s, %s, %s, %s, %s)",
>         (user['user_id'], user['username'], user['email'], user['created_at'], user['status'])
>     )
>
> # Import transactions
> for txn in valid_transactions:
>     cur.execute(
>         "INSERT INTO transactions (transaction_id, user_id, amount, timestamp, description) VALUES (%s, %s, %s, %s, %s)",
>         (txn['transaction_id'], txn['user_id'], txn['amount'], txn['timestamp'], txn['description'])
>     )
>
> conn.commit()
> cur.close()
> conn.close()
>
> print("Data imported successfully")
> EOF
root@5dedd0e6de41:/backup# python3 /backup/clean_and_import.py; tmux wait -S done
Traceback (most recent call last):
  File "/backup/clean_and_import.py", line 4, in <module>
    import psycopg2
ModuleNotFoundError: No module named 'psycopg2'
root@5dedd0e6de41:/backup# pip3 install psycopg2-binary; tmux wait -S done
bash: pip3: command not found
root@5dedd0e6de41:/backup# python3 /backup/clean_and_import.py; tmux wait -S done
Traceback (most recent call last):
  File "/backup/clean_and_import.py", line 4, in <module>
    import psycopg2
ModuleNotFoundError: No module named 'psycopg2'
root@5dedd0e6de41:/backup# cat > /backup/clean_data.py << 'EOF'
> import csv
> import json
>
> # Clean users CSV
> valid_users = []
> with open('/backup/users_export.csv', 'r') as f:
>     reader = csv.DictReader(f)
>     for row in reader:
>         # Check for missing user_id
>         if not row.get('user_id') or not row['user_id'].strip():
>             continue
>         # Check for empty username
>         if not row.get('username') or not row['username'].strip():
>             continue
>         # Check for invalid email (must contain @)
>         if not row.get('email') or '@' not in row['email']:
>             continue
>         # Check for invalid status
>         status = row.get('status', '').strip()
>         if status not in ['active', 'inactive', 'suspended']:
>             continue
>         valid_users.append(row)
>
> # Write cleaned users to CSV
> with open('/backup/clean_users.csv', 'w', newline='') as f:
>     writer = csv.DictWriter(f, fieldnames=['user_id', 'username', 'email', 'created_at', 'status'])
>     writer.writeheader()
>     writer.writerows(valid_users)
>
> print(f"Cleaned {len(valid_users)} valid users")
>
> # Clean transactions JSON
> with open('/backup/transactions_backup.json', 'r') as f:
>     transactions = json.load(f)
>
> valid_transactions = []
> for txn in transactions:
>     # Check for null transaction_id
>     if txn.get('transaction_id') is None:
>         continue
>     # Check for null or negative amounts
>     amount = txn.get('amount')
>     if amount is None or amount <= 0:
>         continue
>     # Check for missing timestamp
>     if not txn.get('timestamp'):
>         continue
>     # Check for valid user_id (1-30)
>     user_id = txn.get('user_id')
>     if user_id is None or user_id < 1 or user_id > 30:
>         continue
>     valid_transactions.append(txn)
>
> # Write valid transactions to JSON
> with open('/backup/valid_transactions.json', 'w') as f:
>     json.dump(valid_transactions, f, indent=2)
>     f.write('\n')
>
> print(f"Cleaned {len(valid_transactions)} valid transactions")
> EOF
root@5dedd0e6de41:/backup# python3 /backup/clean_data.py; tmux wait -S done
Cleaned 30 valid users
Traceback (most recent call last):
  File "/backup/clean_data.py", line 43, in <module>
    if amount is None or amount <= 0:
                         ^^^^^^^^^^^
TypeError: '<=' not supported between instances of 'str' and 'int'
root@5dedd0e6de41:/backup# head -10 /backup/clean_users.csv; tmux wait -S done
user_id,username,email,created_at,status
1,alice_smith,alice_smith@example.com,2024-11-21 01:25:46,inactive
2,bob_jones,bob_jones@example.com,2025-06-28 01:25:46,active
3,charlie_brown,charlie_brown@example.com,2025-08-13 01:25:46,suspended
4,diana_prince,diana_prince@example.com,2025-08-05 01:25:46,inactive
5,eve_adams,eve_adams@example.com,2025-09-08 01:25:46,inactive
6,frank_white,frank_white@example.com,2025-09-04 01:25:46,active
7,grace_lee,grace_lee@example.com,2025-06-05 01:25:46,active
8,henry_ford,henry_ford@example.com,2025-07-25 01:25:46,inactive
9,iris_west,iris_west@example.com,2025-03-23 01:25:46,suspended
root@5dedd0e6de41:/backup# cat > /backup/clean_data.py << 'EOF'
> import csv
> import json
>
> # Clean users CSV
> valid_users = []
> with open('/backup/users_export.csv', 'r') as f:
>     reader = csv.DictReader(f)
>     for row in reader:
>         # Check for missing user_id
>         if not row.get('user_id') or not row['user_id'].strip():
>             continue
>         # Check for empty username
>         if not row.get('username') or not row['username'].strip():
>             continue
>         # Check for invalid email (must contain @)
>         if not row.get('email') or '@' not in row['email']:
>             continue
>         # Check for invalid status
>         status = row.get('status', '').strip()
>         if status not in ['active', 'inactive', 'suspended']:
>             continue
>         valid_users.append(row)
>
> # Write cleaned users to CSV
> with open('/backup/clean_users.csv', 'w', newline='') as f:
>     writer = csv.DictWriter(f, fieldnames=['user_id', 'username', 'email', 'created_at', 'status'])
>     writer.writeheader()
>     writer.writerows(valid_users)
>
> print(f"Cleaned {len(valid_users)} valid users")
>
> # Clean transactions JSON
> with open('/backup/transactions_backup.json', 'r') as f:
>     transactions = json.load(f)
>
> valid_transactions = []
> for txn in transactions:
>     # Check for null transaction_id
>     if txn.get('transaction_id') is None:
>         continue
>     # Check for null or negative amounts
>     amount = txn.get('amount')
>     if amount is None:
>         continue
>     try:
>         amount_float = float(amount)
>         if amount_float <= 0:
>             continue
>     except (ValueError, TypeError):
>         continue
>     # Check for missing timestamp
>     if not txn.get('timestamp'):
>         continue
>     # Check for valid user_id (1-30)
>     user_id = txn.get('user_id')
>     if user_id is None:
>         continue
>     try:
>         user_id_int = int(user_id)
>         if user_id_int < 1 or user_id_int > 30:
>             continue
>     except (ValueError, TypeError):
>         continue
>     valid_transactions.append(txn)
>
> # Write valid transactions to JSON
> with open('/backup/valid_transactions.json', 'w') as f:
>     json.dump(valid_transactions, f, indent=2)
>     f.write('\n')
>
> print(f"Cleaned {len(valid_transactions)} valid transactions")
> EOF
root@5dedd0e6de41:/backup# python3 /backup/clean_data.py; tmux wait -S done
Cleaned 30 valid users
Cleaned 100 valid transactions
root@5dedd0e6de41:/backup# head -20 /backup/valid_transactions.json; tmux wait -S done
[
  {
    "transaction_id": 1,
    "user_id": 16,
    "amount": 46.0,
    "timestamp": "2025-07-16 01:25:56",
    "description": "Subscription"
  },
  {
    "transaction_id": 2,
    "user_id": 6,
    "amount": 646.05,
    "timestamp": "2025-05-02 01:25:56",
    "description": "Payment"
  },
  {
    "transaction_id": 3,
    "user_id": 29,
    "amount": 186.76,
    "timestamp": "2025-07-30 01:25:56",
root@5dedd0e6de41:/backup# cat > /backup/import_users.sql << 'EOF'
> \COPY users(user_id, username, email, created_at, status) FROM '/backup/clean_users.csv' WITH CSV HEADER;
> EOF
root@5dedd0e6de41:/backup# psql -U postgres -d production_db -f /backup/import_users.sql; tmux wait -S done
psql: error: connection to server on socket "/var/run/postgresql/.s.PGSQL.5432" failed: FATAL:  Peer authentication failed for user "postgres"
root@5dedd0e6de41:/backup# cat > /backup/import_transactions.py << 'EOF'
> import json
> import subprocess
>
> # Read valid transactions
> with open('/backup/valid_transactions.json', 'r') as f:
>     transactions = json.load(f)
>
> # Generate SQL INSERT statements
> sql_statements = []
> for txn in transactions:
>     sql = f"INSERT INTO transactions (transaction_id, user_id, amount, timestamp, description) VALUES ({txn['transaction_id']}, {txn['user_id']}, {txn['amount
']}, '{txn['timestamp']}', '{txn['description'].replace("'", "''")}')"
>     sql_statements.append(sql)
>
> # Write SQL file
> with open('/backup/import_transactions.sql', 'w') as f:
>     for sql in sql_statements:
>         f.write(sql + ';\n')
>
> print(f"Generated SQL for {len(transactions)} transactions")
> EOF
root@5dedd0e6de41:/backup# python3 /backup/import_transactions.py; tmux wait -S done
Generated SQL for 100 transactions
root@5dedd0e6de41:/backup# psql -U postgres -d production_db -f /backup/import_transactions.sql; tmux wait -S done
psql: error: connection to server on socket "/var/run/postgresql/.s.PGSQL.5432" failed: FATAL:  Peer authentication failed for user "postgres"
root@5dedd0e6de41:/backup# psql -U postgres -d production_db -c "SELECT COUNT(*) FROM users;"; tmux wait -S done
psql: error: connection to server on socket "/var/run/postgresql/.s.PGSQL.5432" failed: FATAL:  Peer authentication failed for user "postgres"
root@5dedd0e6de41:/backup# psql -U postgres -d production_db -c "SELECT COUNT(*) FROM transactions;"; tmux wait -S done
psql: error: connection to server on socket "/var/run/postgresql/.s.PGSQL.5432" failed: FATAL:  Peer authentication failed for user "postgres"
root@5dedd0e6de41:/backup# sudo -u postgres psql -d production_db -f /backup/import_users.sql; tmux wait -S done
bash: sudo: command not found
root@5dedd0e6de41:/backup# sudo -u postgres psql -d production_db -f /backup/import_transactions.sql; tmux wait -S done
bash: sudo: command not found
root@5dedd0e6de41:/backup# sudo -u postgres psql -d production_db -c "SELECT COUNT(*) FROM users;"; tmux wait -S done
bash: sudo: command not found
root@5dedd0e6de41:/backup# sudo -u postgres psql -d production_db -c "SELECT COUNT(*) FROM transactions;"; tmux wait -S done
bash: sudo: command not found
root@5dedd0e6de41:/backup# su - postgres -c "psql -d production_db -f /backup/import_users.sql"; tmux wait -S done
psql: error: connection to server on socket "/var/run/postgresql/.s.PGSQL.5432" failed: FATAL:  database "production_db" does not exist
root@5dedd0e6de41:/backup# su - postgres -c "psql -d production_db -f /backup/import_transactions.sql"; tmux wait -S done
psql: error: connection to server on socket "/var/run/postgresql/.s.PGSQL.5432" failed: FATAL:  database "production_db" does not exist
root@5dedd0e6de41:/backup# su - postgres -c "psql -d production_db -c 'SELECT COUNT(*) FROM users;'"; tmux wait -S done
psql: error: connection to server on socket "/var/run/postgresql/.s.PGSQL.5432" failed: FATAL:  database "production_db" does not exist
root@5dedd0e6de41:/backup# su - postgres -c "psql -d production_db -c 'SELECT COUNT(*) FROM transactions;'"; tmux wait -S done
psql: error: connection to server on socket "/var/run/postgresql/.s.PGSQL.5432" failed: FATAL:  database "production_db" does not exist
root@5dedd0e6de41:/backup# su - postgres -c "psql -c 'CREATE DATABASE production_db;'"; tmux wait -S done
CREATE DATABASE
root@5dedd0e6de41:/backup# su - postgres -c "psql -d production_db -f /backup/database.sql"; tmux wait -S done
CREATE TABLE
CREATE TABLE
root@5dedd0e6de41:/backup# su - postgres -c "psql -d production_db -f /backup/import_users.sql"; tmux wait -S done
COPY 30
root@5dedd0e6de41:/backup# su - postgres -c "psql -d production_db -f /backup/import_transactions.sql"; tmux wait -S done
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
root@5dedd0e6de41:/backup# su - postgres -c "psql -d production_db -c 'SELECT COUNT(*) FROM users;'"; tmux wait -S done
 count
-------
    30
(1 row)

root@5dedd0e6de41:/backup# su - postgres -c "psql -d production_db -c 'SELECT COUNT(*) FROM transactions;'"; tmux wait -S done
 count
-------
   100
(1 row)

root@5dedd0e6de41:/backup# cat > /backup/generate_reports.py << 'EOF'
> import subprocess
> import json
>
> # Generate database statistics report
> result = subprocess.run(
>     ['su', '-', 'postgres', '-c',
>      "psql -d production_db -t -A -F'|' -c 'SELECT COUNT(*) FROM users; SELECT COUNT(*) FROM users WHERE status=\\'active\\'; SELECT COUNT(*) FROM transaction
s; SELECT SUM(amount) FROM transactions; SELECT SUM(amount)/COUNT(DISTINCT user_id) FROM transactions;'"],
>     capture_output=True, text=True
> )
>
> lines = result.stdout.strip().split('\n')
> total_users = lines[0]
> active_users = lines[1]
> total_transactions = lines[2]
> total_amount = float(lines[3])
> avg_per_user = float(lines[4])
>
> with open('/backup/db_stats.txt', 'w') as f:
>     f.write('DATABASE STATISTICS\n')
>     f.write('==================\n')
>     f.write(f'Total Users: {total_users}\n')
>     f.write(f'Active Users: {active_users}\n')
>     f.write(f'Total Transactions: {total_transactions}\n')
>     f.write(f'Total Amount: {total_amount:.2f}\n')
>     f.write(f'Average per User: {avg_per_user:.2f}\n')
>
> print('Generated db_stats.txt')
>
> # Generate top users report
> result = subprocess.run(
>     ['su', '-', 'postgres', '-c',
>      "psql -d production_db -t -A -F',' -c 'SELECT u.username, SUM(t.amount) as total_amount FROM users u JOIN transactions t ON u.user_id = t.user_id GROUP B
Y u.username ORDER BY total_amount DESC, u.username ASC LIMIT 10;'"],
>     capture_output=True, text=True
> )
>
> with open('/backup/top_users.csv', 'w') as f:
>     f.write('username,total_amount\n')
>     for line in result.stdout.strip().split('\n'):
>         if line:
>             parts = line.split(',')
>             username = parts[0]
>             amount = float(parts[1])
>             f.write(f'{username},{amount:.2f}\n')
>
> print('Generated top_users.csv')
> EOF
root@5dedd0e6de41:/backup# python3 /backup/generate_reports.py; tmux wait -S done
Traceback (most recent call last):
  File "/backup/generate_reports.py", line 13, in <module>
    active_users = lines[1]
                   ~~~~~^^^
IndexError: list index out of range
root@5dedd0e6de41:/backup# cat /backup/db_stats.txt; tmux wait -S done
cat: /backup/db_stats.txt: No such file or directory
root@5dedd0e6de41:/backup# cat /backup/top_users.csv; tmux wait -S done
cat: /backup/top_users.csv: No such file or directory
root@5dedd0e6de41:/backup# cat > /backup/generate_reports.py << 'EOF'
> import subprocess
>
> # Function to run SQL query
> def run_query(query):
>     result = subprocess.run(
>         ['su', '-', 'postgres', '-c', f"psql -d production_db -t -A -c \"{query}\""],
>         capture_output=True, text=True
>     )
>     return result.stdout.strip()
>
> # Get statistics
> total_users = run_query('SELECT COUNT(*) FROM users;')
> active_users = run_query("SELECT COUNT(*) FROM users WHERE status='active';")
> total_transactions = run_query('SELECT COUNT(*) FROM transactions;')
> total_amount = float(run_query('SELECT SUM(amount) FROM transactions;'))
> avg_per_user = float(run_query('SELECT SUM(amount)/COUNT(DISTINCT user_id) FROM transactions;'))
>
> # Write database statistics
> with open('/backup/db_stats.txt', 'w') as f:
>     f.write('DATABASE STATISTICS\n')
>     f.write('==================\n')
>     f.write(f'Total Users: {total_users}\n')
>     f.write(f'Active Users: {active_users}\n')
>     f.write(f'Total Transactions: {total_transactions}\n')
>     f.write(f'Total Amount: {total_amount:.2f}\n')
>     f.write(f'Average per User: {avg_per_user:.2f}\n')
>
> print('Generated db_stats.txt')
>
> # Get top users
> top_users_query = "SELECT u.username, SUM(t.amount) as total_amount FROM users u JOIN transactions t ON u.user_id = t.user_id GROUP BY u.username ORDER BY tot
al_amount DESC, u.username ASC LIMIT 10;"
> result = subprocess.run(
>     ['su', '-', 'postgres', '-c', f"psql -d production_db -t -A -F',' -c \"{top_users_query}\""],
>     capture_output=True, text=True
> )
>
> # Write top users CSV
> with open('/backup/top_users.csv', 'w') as f:
>     f.write('username,total_amount\n')
>     for line in result.stdout.strip().split('\n'):
>         if line:
>             parts = line.split(',')
>             username = parts[0]
>             amount = float(parts[1])
>             f.write(f'{username},{amount:.2f}\n')
>
> print('Generated top_users.csv')
> EOF
root@5dedd0e6de41:/backup# python3 /backup/generate_reports.py; tmux wait -S done
Generated db_stats.txt
Generated top_users.csv
root@5dedd0e6de41:/backup# cat /backup/db_stats.txt; tmux wait -S done
DATABASE STATISTICS
==================
Total Users: 30
Active Users: 13
Total Transactions: 100
Total Amount: 53109.46
Average per User: 1770.32
root@5dedd0e6de41:/backup# cat /backup/top_users.csv; tmux wait -S done
username,total_amount
zara_ahmed,4400.17
alice_smith,3682.87
victor_von,3451.21
donna_noble,3225.49
xavier_prof,2990.51
nick_fury,2709.20
wade_wilson,2678.95
tony_stark,2637.00
frank_white,2539.97
charlie_brown,2525.32
root@5dedd0e6de41:/backup# cat /backup/backup_metadata.log; tmux wait -S done
[2025-09-28 03:00:00] INFO: Starting database backup process
[2025-09-28 03:00:01] INFO: Backup initiated by: admin
[2025-09-28 03:00:01] INFO: Backup type: Full
[2025-09-28 03:00:02] INFO: Connecting to database: production_db
[2025-09-28 03:00:03] INFO: Connection successful
[2025-09-28 03:00:05] INFO: Backing up table: users
[2025-09-28 03:00:06] INFO: Table 'users' backed up successfully - 30 rows
[2025-09-28 03:00:07] INFO: Backing up table: transactions
[2025-09-28 03:00:09] INFO: Table 'transactions' backed up successfully - 100 rows
[2025-09-28 03:00:10] INFO: Total tables backed up: 2
[2025-09-28 03:00:10] INFO: Total rows backed up: 130
[2025-09-28 03:00:11] INFO: Running integrity check
[2025-09-28 03:00:12] INFO: Integrity check: PASSED
[2025-09-28 03:00:13] INFO: Backup completed successfully
[2025-09-28 03:00:13] INFO: Backup file: /backup/database.sql
[2025-09-28 03:00:13] INFO: Backup timestamp: 2025-09-28 03:00:00
root@5dedd0e6de41:/backup# cat > /backup/generate_verification.py << 'EOF'
> import re
>
> # Read backup metadata log
> with open('/backup/backup_metadata.log', 'r') as f:
>     content = f.read()
>
> # Extract information using regex or line parsing
> backup_date = ''
> tables_backed_up = ''
> total_rows = ''
> integrity_check = ''
>
> for line in content.split('\n'):
>     if 'Backup timestamp:' in line:
>         backup_date = line.split('Backup timestamp:')[1].strip()
>     elif 'Total tables backed up:' in line:
>         tables_backed_up = line.split('Total tables backed up:')[1].strip()
>     elif 'Total rows backed up:' in line:
>         total_rows = line.split('Total rows backed up:')[1].strip()
>     elif 'Integrity check:' in line:
>         integrity_check = line.split('Integrity check:')[1].strip()
>
> # Write backup verification report
> with open('/backup/backup_verification.txt', 'w') as f:
>     f.write('BACKUP VERIFICATION\n')
>     f.write('===================\n')
>     f.write(f'Backup Date: {backup_date}\n')
>     f.write(f'Tables Backed Up: {tables_backed_up}\n')
>     f.write(f'Total Rows: {total_rows}\n')
>     f.write(f'Integrity Check: {integrity_check}\n')
>
> print('Generated backup_verification.txt')
> EOF
root@5dedd0e6de41:/backup# python3 /backup/generate_verification.py; tmux wait -S done
Generated backup_verification.txt
root@5dedd0e6de41:/backup# cat /backup/backup_verification.txt; tmux wait -S done
BACKUP VERIFICATION
===================
Backup Date: 2025-09-28 03:00:00
Tables Backed Up: 2
Total Rows: 130
Integrity Check: PASSED
root@5dedd0e6de41:/backup# echo 'RECOVERY_SUCCESSFUL' > /backup/recovery_complete.txt; tmux wait -S done
root@5dedd0e6de41:/backup# ls -la /backup/*.txt /backup/*.csv /backup/*.json; tmux wait -S done
-rw-r--r-- 1 root root   133 Dec  4 17:56 /backup/backup_verification.txt
-rw-r--r-- 1 root root  2052 Dec  4 17:55 /backup/clean_users.csv
-rw-r--r-- 1 root root   145 Dec  4 17:56 /backup/db_stats.txt
-rw-r--r-- 1 root root    20 Dec  4 17:56 /backup/recovery_complete.txt
-rw-r--r-- 1 root root   219 Dec  4 17:56 /backup/top_users.csv
-rw-r--r-- 1 root root 15425 Dec  4 16:54 /backup/transactions_backup.json
-rw-r--r-- 1 root root  2351 Dec  4 16:54 /backup/users_export.csv
-rw-r--r-- 1 root root 14573 Dec  4 17:55 /backup/valid_transactions.json
root@5dedd0e6de41:/backup# cat /backup/recovery_complete.txt; tmux wait -S done
RECOVERY_SUCCESSFUL
root@5dedd0e6de41:/backup# su - postgres -c "psql -d production_db -c 'SELECT COUNT(*) FROM users; SELECT COUNT(*) FROM transactions;'"; tmux wait -S done
 count
-------
    30
(1 row)

 count
-------
   100
(1 row)

root@5dedd0e6de41:/backup# wc -l /backup/clean_users.csv /backup/top_users.csv; tmux wait -S done
  31 /backup/clean_users.csv
  11 /backup/top_users.csv
  42 total
root@5dedd0e6de41:/backup# tail -c 1 /backup/clean_users.csv | od -An -tx1; tmux wait -S done
 0a
root@5dedd0e6de41:/backup# tail -c 1 /backup/valid_transactions.json | od -An -tx1; tmux wait -S done
 0a
root@5dedd0e6de41:/backup# tail -c 1 /backup/db_stats.txt | od -An -tx1; tmux wait -S done
 0a
root@5dedd0e6de41:/backup# tail -c 1 /backup/top_users.csv | od -An -tx1; tmux wait -S done
 0a
root@5dedd0e6de41:/backup# tail -c 1 /backup/backup_verification.txt | od -An -tx1; tmux wait -S done
 0a
root@5dedd0e6de41:/backup# tail -c 1 /backup/recovery_complete.txt | od -An -tx1; tmux wait -S done
 0a
root@5dedd0e6de41:/backup# echo 'All files verified and tasks complete!'; tmux wait -S done
All files verified and tasks complete!
root@5dedd0e6de41:/backup#
